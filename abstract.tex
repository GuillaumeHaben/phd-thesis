  \chapter*{Abstract}

Many companies rely on software testing to verify that their software products meet their requirements. However, test quality and, in particular, the quality of test interacting with the graphical user interface (GUI), i.e. system user interactive tests (SUITs), is relatively hard to achieve. The problem becomes challenging when software evolves, as SUIT suites need to adapt and conform to the evolved software. Unfortunately, SUITs are particularly fragile as any change in the application interface, e.g., application flow, location or name of graphical user interface elements, necessitates a change in the tests. 

In this dissertation, we present an empirical evaluation on the impact of the evolution and the maintenance of SUIT suites. Our aim is to demonstrate the problem of test maintenance and overall improve the understanding of test code evolution. To this end, we identify, collect and analyze test code changes across the evolution of an industrial test suite. We show that the problem of test maintenance is largely due to test fragility (most commonly-performed changes are due to locator and synchronization issues) and test clones (over 30\% of keywords are duplicated). 

To further investigate the question of bad test code practices such as test clones, we perform a multivocal study to identify which bad practices, test code smells, are already studied in both industry academia and establish a list of 35 test code smells. For 16 of them, we derive metrics to analyze their diffusion across tests as well as potential refactoring actions removing the test code smells. Conducting a second empirical study, including both industrial and open-source test suites, we show that test code smells are largely present in SUITs, potentially contributing to the fragility and hindering the maintenance process.

However, during the analysis of SUIT smells, we observe that bad practice impacting locators does not appear often in the test code, which seems to contrast with the analysis of the evolution of the SUIT presented in our first empirical study.  This apparent contradiction arises from the limitation of current techniques to actually account for evolution of the test. Thus, good locators do not imply their robustness to non-functional changes in the application. To account for this limitation in current approaches, we introduce a new way of expressing locators, HPath, which instead of relying on the internal representation of the GUI relies on rendered characteristics, thus generating locators that are independent to the internal details of the application. Our results show that in spite of what the grey literature on smells suggest, locators relying on a smaller number of GUI elements to fully qualify a target do not necessarily lead to more robust locators, but the choice of the GUI element properties has a much stronger impact.
