\chapter*{Abstract}

% Through an ensemble of techniques and methodologies, software engineering enables the creation of high-quality software: reliable, efficient, maintainable, scalable, as well as cost-effective and delivered on time.
% Modern software engineering involves a range of activities, including requirements analysis, design, coding, testing, and maintenance. These latter aspects are often performed in continuous integration, a development practice that aims at automating builds, testing and frequent code change to speed up the development cycle.
% In this context, 
Software testing plays a crucial role to guarantee a desired level of software quality. Its goal is to ensure software products respect specified requirements, function as intended and are error-free. The scope of software testing is broad, from functional to non-functional requirements, and is generally performed at different levels (\eg unit testing, integration testing, system testing, acceptance testing). During continuous integration, development activities are typically stopped when test failures happen and further investigations and debugging are required.

In an ideal world, all tests are deterministic: developers and testers expect the same outcome (pass or fail) for a test when executed twice on the same version of their program. Unfortunately, some tests exhibit non-deterministic behaviour. Commonly named flaky tests, they give confusing signals to developers who struggle to understand if their software is defective or not, and tend to lower their trust in test suites. Those occasional test failures can be difficult to reproduce and thus hard to debug. When test flakiness is left unaddressed, it can hinder smooth and rapid integration of code changes. Furthermore, it also impacts many effective testing techniques such as test case selection, test case prioritisation, automated program repair and fault detection. While the phenomenon is known by many for decades now, academic attention has only sprouted in the recent years and few studies were carried out to better understand flakiness, its different causes and origins, and to propose techniques helping to prevent, detect and mitigate flakiness. 

In this context, the present dissertation aims at advancing research in test flakiness through five contributions. By conducting a qualitative study, the first contribution seeks to understand practitioners' perceptions of the sources, impact and mitigation strategies of flaky tests. The goal of this work is to grasp the current challenges revolving around flakiness in the industry and to identify opportunities for future research. We carried out this study by conducting a grey literature review and practitioner interviews. Findings revealed sources of flakiness that were until now overlooked by previous research (such as the infrastructure, environment or testing frameworks) and a strong negative impact on testing practices. 
% We also identified opportunities for automated techniques based on the need for rigorous monitoring, analysis and quality assessment.

The following three contributions aim at predicting different aspects of test flakiness. At the moment, rerunning failing tests is the main approach to deal with flakiness but it comes at a cost, both time-wise and computer-wise. If accurate, predicting flaky tests can be an alternative to reruns and help better understand their characteristics. We first replicate an existing approach relying on code vocabulary to predict flaky tests with three goals in mind: validating the approach in the continuous integration context, evaluating the generalisability of the approach to different programming languages and extending the approach by considering an additional set of features. Realising that predicting flaky tests is feasible but challenges remain to understand the cause of flakiness, we next present a new technique to predict the flakiness category of a given flaky test with the hope to provide developers with better insights to debug their tests. Next, with real-world use cases in mind, we conduct an empirical analysis of Chromium's continuous integration, where we found that flaky test signals should not be discarded as they reveal themselves useful to find faults caused  by regressions. Thus, we advocate for the need to predict failures (as flaky or faulty) by taking into account the context of a test's execution.

Finally, the last contribution of this dissertation aims at identifying the cause of flakiness in the critical case where its source originates from within the program under test. To do so, we adapt spectrum-based fault localisation and leverage ensemble learning to rank classes based on their likelihood to be responsible for test flakiness. 

Overall, this thesis provides insights on how predictive models can be leveraged to better handle test flakiness in real-world contexts.  