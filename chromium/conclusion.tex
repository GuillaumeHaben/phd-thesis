\section{Conclusion}
\label{sec:chromium-conclusion}

In this paper, we investigated the utility of existing vocabulary-based flaky test prediction methods in the context of a continuous integration pipeline. To do so, we collected data about 23,374 flaky tests and 2,343 fault-revealing tests composing a dataset of 1.8 million test failures representing the actual development process of more than 10,000 builds corresponding to a period of 9 months. Thus, we empirically evaluated the prediction methods and found similar performance compared to previous studies in terms of precision and recall. Despite the (very) high accuracy to detect flaky test failures, we also found that 76.2\% of fault-triggering test failures were misclassified as flaky by the prediction methods, indicating major losses on the fault revelation capabilities of the test suites. Going a step further, we also showed that flaky tests have a strong ability to detect faults, with \nicefrac{1}{3} of all regression faults being revealed by tests that have experienced flaky behaviour at some point in the lifetime of the project under analysis.

These findings motivated the need for failure-focused prediction methods. To this end, we extended our analysis by checking the performance of failure-focused models (trained on failures instead of tests) and found that they result in similar accuracy and fewer false positives. We also found that considering test execution features such as the run duration and the historical flake rate was helpful to increase its ability to discern flaky failures and fault-triggering failures. However, our results still miss a large number of test failures, 42.3\%. Therefore, we believe that the current performance is not actionable and that additional research is needed in order to tackle this vastly ignored problem of flaky test failure prediction over flaky tests.

Our future research agenda aims at improving the performance of flaky test failure detection techniques by using additional features and artificial data (augmenting the training data with new positive examples to tackle the class imbalance issues). We also plan to develop failure-cause interpretations for the techniques so that they could be usable by the Chromium developers.  