\chapter{Conclusion}
\label{chap:conclusion}

\chapterPage{
This chapter presents the overall conclusion of the dissertation and proposes potential research directions. 
}

\section{Summary of contributions}

In this dissertation, we presented studies, techniques, and tools that contribute to reducing the maintenance cost that is associated with the evolution of \gls{suit}s. Indeed, with the increased adoption of Agile and DevOps methodologies, quick and reliable test feedback on every code change becomes essential, leading SUITs to evolve continuously alongside the system they exercise. However,  the user interface is a part of the system that tends to undergo rapid evolutions, causing \gls{suit}s to be particularly prompt to break. In this context, this dissertation brings the following contribution: (1) an empirical study that evaluates how \gls{suit}s evolve in a large industrial system; (2) an empirical study that measures the prevalence of bad design practices potentially contributing to test fragility and their higher maintenance cost; and (3) a novel approach to render \gls{suit}s more resistant to \gls{sut} evolution by creating more robust locators.

The goal of the first contribution is to shed light on how and why \gls{suit}s undergo heavy maintenance. Our analysis reveals that test fragility (the sensitivity to \gls{sut} evolution) and test clones (keywords with similar test functionality) are the most important problems of \gls{kdt}. On the positive side, our study provides evidence that following the good design practices of \gls{kdt} (such as the separation of concern and the reusability of keywords) has the potential to reduce the required number of maintenance changes. Our analysis shows that this reduction is approximately 70\% demonstrating major benefits of \gls{kdt}. Our results also help to improve the understanding of the fine-grained changes performed during the evolution of \gls{kdt}.  We provide a taxonomy of test code changes and reveal the presence of test clones caused by the difficulty of selecting appropriate keywords. We believe that the main drawback of \gls{kdt} lies in the absence of appropriate tooling, allowing to deal with test code growth, navigation, and comprehension. To address this concern, we introduce \tool\, an automated approach to provide testers with visibility on their test codebase. Finally, we show that practitioners agree with the promises of \gls{kdt}, on the advantages of the separation of concerns and the reusability of keywords. 

%Furthermore, we observe that test fragility causes a constant test adaptation (even in response to simple \gls{gui} changes) and that test clones are prominent. We show that over 90\% of the project keywords are changed and over 30\% of the the keywords are clones. We also find that among identical clones, 50\% of them co-evolve. These findings indicate the need for automated test repair and refactoring techniques.  

With the second contribution, our objectives were to better understand which sub-optimal decision within the test code could have an effect on the maintenance by measuring the diffusion of bad practices and their refactoring from the test codebase. To achieve these goals, we combine a multi-vocal literature review and an empirical study on a large industrial project and 12 open-source repositories.
Relying on the multivocal literature review, we build a catalog of 35 \gls{suit} smells. For 12 out of 35 of the smells from this catalog, we propose an automated approach for detecting the introduction and refactoring of these \gls{suit} smells. Leveraging on this approach, we evaluate the prevalence of \gls{suit} smells and their refactoring in our industrial and open-source projects. Even though our empirical results suggest that most tests present the symptoms of bad practices, less than half of them ever experience refactoring during their lifespan. However, while refactoring actions are rare, \gls{suit} smells like \emph{Narcissistic} and \emph{Middle Man} still disappear from the code base as a side effect of unintended maintenance and removal of symptomatic tests and the apparition of clean ones.

Finally, the third contribution tackles the breakages caused by second-generation locators. Because they rely heavily on internal properties of the elements they visit, second-generation locators can be problematic in the case of automated \gls{gui} testing as it leaks structural details of the \gls{sut} that should not be present in such tests. We propose HPath, a second-generation locator inspired by third-generation locators which avoid exposing internal details to the test by relying only on the rendered properties of the \gls{sut}. The practical benefits of HPath can be measured via its capability to generate more flexible locators than the current second-generation techniques. The results from our experiments suggest that HPath is able to reduce test breakages compared to classical approaches relying on internal properties. However, while the results are promising, for HPath to be useful when developing the user interface, developers need to rely on modern implementation of the \gls{html} standard and follow good practices.

\section{Perspectives}

In the following, we discuss potential future research that follows the contributions and ideas presented in this dissertation:

\begin{itemize}
    \item \textbf{Improvements on locators representation:} In Chapter~\ref{chap:robust-locators}, we propose an approach to exploit properties that make third-generation locators more robust to change and integrate them into second-generation locators. Unfortunately, many current frameworks do not allow for the extraction of the representation layer in a way that allows relying on second-generation locators. While relying only on \gls{vgt} offers promising results, the model extracted by the current computer vision techniques remains unable to adapt to trivial changes in the rendering of the \gls{sut}. By generalizing the concept of rendering tree and proposing a common representation applicable to all \gls{gui}-based applications, the shortcoming of third-generation locators could be alleviated. We envision two possible paths leading to the generation of a general tree representation: (1) computer vision and similar tooling can be employed to extract the hierarchical structure of the \gls{gui}, therefore, leading to a partial rendering tree; (2) by exposing the rendering engines present in web browsers and other applications, testing tools can extract the intermediate representation of the \gls{gui} and interact with it. Again, each solution comes with advantages and limitations necessitating future research.
    
    \item \textbf{Test execution analysis:} In Chapter~\ref{chap:smells-system-user-interactive-test}, we present an exploratory analysis of the diffusion and the refactoring of bad practices in \gls{suit}s. In an attempt to better understand their impact on \gls{suit} maintenance and derive solutions allowing to avoid it, we conduct a deeper analysis of the effects associated with two of \gls{suit} smells: code duplication (Section~\ref{sec:evolution-results-rq3}) and fragile locator representation (Chapter~\ref{chap:robust-locators}). However, testers at \BGL\ refer to a third major cause leading to high maintenance, synchronization with the \gls{sut}. Indeed, when not carefully crafted (\eg \emph{Stinky Synchronization Syndrom} in Section~\ref{sec:results-smells-catalog}), tests may fail in a non-deterministic manner because of the variability in factors outside the scope of the test. This happens because \gls{suit}s rely on the system as a whole and operate asynchronously from the \gls{sut}. Therefore, they are sensitive to variations and non-determinism occurring either in the \gls{sut} or the infrastructure it relies on. This leads us to define three root causes for \gls{suit} failures: (1) test breakage resulting from a mismatch between the test and the \gls{sut}; (2) flaky failures resulting from variations in the \gls{sut} or in the infrastructure leading to false alarms; and (3) failures resulting from a fault present in the \gls{sut} which is the only type of test failure providing the signal intended by the test. Moreover, even when the failure is revealing a fault in the \gls{sut}, because of the size of the test, isolating the sub-system(s) responsible for the failure becomes challenging. Indeed, as shown in Chapter~\ref{chap:evolution-system-user-interactive-test} and Chapter~\ref{chap:related-work}, a single test can exercise tens or even hundreds of interactions with the \gls{sut}. Consequently, we advocate for more research on the automatic analysis of test failures as the signal provided by the failure itself remains limited. Instead of mimicking the behavior of unit tests, \gls{suit} report could be associated with more contextual information about the failure, its root causes, and potentially offer a triage mechanism to redirect the type of failure into categories or trace it back to the sub-system at fault.
\end{itemize}
