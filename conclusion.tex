\chapter{Conclusion}
\label{chap:conclusion}

\section{Summary of contributions}

In this dissertation, we presented studies, techniques and tools that contribute to reduce the maintenance cost that is associated with the evolution of \gls{suit}s. Indeed, with the increased adoption of Agile and DevOps methodologies, quick and reliable test feedback on every code change becomes essential, leading SUITs to evolve continuously alongside the system they exercise. However,  the user interface is a part of the system that tends to undergo rapid evolutions, causing \gls{suit}s to be particularly prompt to break. In this context, this dissertation brings the following contribution: (1) An empirical study that evaluates how \gls{suit}s evolve in a large industrial system; (2) An empirical study that measure the prevalence of bad design practices potentially contributing to test fragility and their higher maintenance cost; and (3) a novel approach to render \gls{suit}s more resistant to \gls{sut} evolution by creating more robust locators.

The goal of the first contribution is to shed light on how and why \gls{suit}s undergo heavy maintenance. Our analysis reveals that test fragility (the sensitivity to \gls{sut} evolution) and test clones (keywords with similar test functionality) are the most important problems of \gls{kdt}, while at the same time following the good practices encouraged by \gls{kdt} offers major opportunities for test code reuse. On the positive side, our study provides evidence that following the good design practices of \gls{kdt} (such as  the  separation of concern and the reusability of keywords) has the potential to reduce the required number of maintenance changes. Our analysis shows that this reduction is approximately 70\% demonstrating major benefits of \gls{kdt}. Our results also help improving the understanding on the fine-grain changes performed during the evolution of \gls{kdt}.  We provide a taxonomy of test code changes and reveal the presence of test clones caused by the difficulty of selecting appropriate keywords. We believe that the main drawback of \gls{kdt} lies in the absence of appropriate tooling, allowing to deal with test code growth, navigation and comprehension. To answer this concern, we introduce \tool\ which provides testers with visibility on their test code base. Finally, we show that practitioners agree with the promises of \gls{kdt}, on the advantages of the separation of concern and the reusability of keywords. 

%Furthermore, we observe that test fragility causes a constant test adaptation (even in response to simple \gls{gui} changes) and that test clones are prominent. We show that over 90\% of the project keywords are changed and over 30\% of the the keywords are clones. We also find that among identical clones, 50\% of them co-evolve. These findings indicate the need for automated test repair and refactoring techniques.  

With the second contribution, our objectives were to better understand which sub-optimal decision within the test code could have an effect on the maintenance by measuring the diffusion of symptoms of bad practices and their refactoring from the test code base. To achieve these goals, we combine a multi-vocal literature review and an empirical study on a large industrial project and 12 open-source repositories.
Relying on the multivocal literature review, we build a catalogue of 35 \gls{suit} smells. For 12 out of 35 of the smells from this catalogue, we propose an automated approach for detecting the introduction and refactoring of these \gls{suit} smells. Leveraging this  approach, we evaluate the prevalence of \gls{suit} smells and their refactoring in our industrial and open-source projects. Even though our empirical results suggest that most test present the symptoms of bad practices, less than half of them ever experience refactoring during their life span. However, while refactoring actions are rare, \gls{suit} smells like \emph{Narcissistic} and \emph{Middle Man} still disappear from the code base as a side effect of unintended maintenance and removal of symptomatic tests and the apparition of new ones not exhibiting the symptoms.

Finally, the third contribution tackles the breakages caused by \gls{dom}-based locators. Because they rely heavily on internal properties of the elements they visit, this approach can be problematic in the case of automated GUI testing as it leaks structural details of the \gls{sut} that should not be present in such tests. We propose HPath, a \gls{dom}-based locators inspired by third-generation locators which avoid leaking internal details by relying only on the rendered nodes and properties from the \gls{dom}. The practical benefits of HPath can be measured via its capability to generate more flexible locators than the current second-generation techniques. The results from our experimentation suggest that HPath is able to reduce test breakages compared to classical approaches relying on internal properties. However, while the results are promising, for HPath to be useful, when developing the user interface, developers need to rely on modern implementation of the \gls{html} standard and follow good practices.

\section{Perspectives}

%Thus, in our short-term future work, we plan to (1) experiment HPath with more application by extending the support of Mercator to other languages implementing the Selenium API, (2) explore more opportunities to generate good predicates relying on heuristics present in the HTML documents such as section titles, overlays, etc. (3) explore ways to generate a rendering tree closer to the GUI components displayed on the screen to better abstract away structural details of the \gls{dom}.