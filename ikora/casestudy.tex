\section{Case Study}

In this section, we present the results generated by \tool~on the \gls{kdt} code base at \BGL. The tool is integrated into their production pipeline where the tool runs nightly (via Jenkins), generating a report with its results. First, the tool checks out all the test projects defined in its configuration file, analyzes them, and generates a report for the automation testers. The report is then deployed on a server accessible by the members of the team. The \gls{kdt} test code is composed of 43 projects accounting for 44,521 lines of test code, 452 test cases, and 4,448 keywords.

Figure~\ref{fig:clones} presents the percentage of clones across all projects. With values of 11.4\% for Type I clone and 27.6\% for Type II clones, we see that there is a high potential for refactoring. This result corroborates previous studies, e.g. \cite{Lavoie2017}, once again highlighting the need for better tooling for automation testers. However, we see that Type III and Type IV clones remain low with values of 0.63\% and 0.0\% respectively. Interviewing the team and analyzing the results, we see that a large portion of the duplicated code is due to the lack of knowledge of the existence of the functionality in the code base, especially in the case of cross-project code duplication.

Figure~\ref{fig:dead-code} shows the number of test code lines never executed (dead code) for each of the 43 projects. The values go as high as 27.2\% of dead code for a project of more than 7000 lines of test code. The main reason for this, as explained by the testers after analyzing the results, is due to refactoring activities. Indeed, in the absence of static analysis tools, during refactoring, deprecated keywords and variables are often kept in fear of breaking production test code.

\tool~has been successfully used by both project managers and automation testers. The former appreciate the clear \gls{kpi}s provided by the report and the latter the information about the locations and causes of the issues reported allowing them to take action if needed. \tool~provides a central point of reference and communication between different roles at \BGL~which is one of the main goals of every continuous inspection tool.

To conclude our evaluation, we asked the users of \tool~which were the main weaknesses or missing features of the tool. According to their answers, the main weaknesses reside in the static nature of the results. Indeed, while the tool provides a snapshot of the state of the code base, the lack of historical data makes it hard to control the evolution of the \gls{kpi}s.