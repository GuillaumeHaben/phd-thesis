@article{Ukkonen1985,
abstract = {The edit distance between strings a1 ... am and b1 ... bn is the minimum cost s of a sequence of editing steps (insertions, deletions, changes) that convert one string into the other. A well-known tabulating method computes s as well as the corresponding editing sequence in time and in space O(mn) (in space O(min(m, n)) if the editing sequence is not required). Starting from this method, we develop an improved algorithm that works in time and in space O(s ?? min(m, n)). Another improvement with time O(s ?? min(m, n)) and space O(s ?? min(s, m, n)) is given for the special case where all editing steps have the same cost independently of the characters involved. If the editing sequence that gives cost s is not required, our algorithms can be implemented in space O(min(s, m, n)). Since s = O(max(m, n)), the new methods are always asymptotically as good as the original tabulating method. As a by-product, algorithms are obtained that, given a threshold value t, test in time O(t ?? min(m, n)) and in space O(min(t, m, n)) whether s ??? t. Finally, different generalized edit distances are analyzed and conditions are given under which our algorithms can be used in conjunction with extended edit operation sets, including, for example, transposition of adjacent characters. ?? 1985 Academic Press, Inc.},
author = {Ukkonen, Esko},
doi = {10.1016/S0019-9958(85)80046-2},
issn = {00199958},
journal = {Information and Control},
month = {1},
number = {1-3},
pages = {100--118},
title = {{Algorithms for approximate string matching}},
volume = {64},
year = {1985}
}

@inproceedings{Myers1992,
address = {New York, New York, USA},
author = {Myers, Brad A. and Rosson, Mary Beth},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '92},
doi = {10.1145/142750.142789},
isbn = {0897915135},
pages = {195--202},
publisher = {ACM Press},
title = {{Survey on user interface programming}},
url = {http://portal.acm.org/citation.cfm?doid=142750.142789},
year = {1992}
}


@article{Myers1994,
author = {Myers, Brad},
doi = {10.1145/174800.174808},
issn = {1072-5520},
journal = {Interactions},
month = {1},
number = {1},
pages = {73--83},
title = {{Challenges of HCI design and implementation}},
volume = {1},
year = {1994}
}


@inproceedings{Baker1995,
author={Baker, B.S.},
booktitle={Reverse Engineering, 1995., Proceedings of 2nd Working Conference on},
title={On finding duplication and near-duplication in large software systems},
year=1995,
pages={86-95},
keywords={program debugging;software tools;system documentation;systems analysis;systems re-engineering;constants;debugging;dup;experimental results;large software systems;redocumentation;software duplication;system reengineering;systematic substitution;variable names;Application software;Computer bugs;Programming profession;Reverse engineering;Scattering parameters;Sections;Software systems;Terminology;White spaces},
doi={10.1109/WCRE.1995.514697},
month={7},
}

@article{Myers1995,
abstract = {Almost as long as there have been user interfaces, there have been special software systems and tools to help design and implement the user interface software. Many of these tools have demonstrated significant productivity gains for programmers, and have become important commercial products. Others have proven less successful at supporting the kinds of user interfaces people want to build. This article discusses the different kinds of user interface software tools, and investigates why some approaches have worked and others have not. Many examples of commercial and research systems are included. Finally, current research directions and open issues in the field are discussed. {\textcopyright} 1995, ACM. All rights reserved.},
author = {Myers, Brad A.},
doi = {10.1145/200968.200971},
issn = {15577325},
journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
keywords = {interface builders,toolkits,user interface development environments,user interface software},
number = {1},
pages = {64--103},
title = {{User Interface Software Tools}},
volume = {2},
year = {1995}
}

@inproceedings{Chawathe1996,
 author = {Chawathe, Sudarshan S. and Rajaraman, Anand and Garcia-Molina, Hector and Widom, Jennifer},
 title = {Change Detection in Hierarchically Structured Information},
 booktitle = {Proceedings of the 1996 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '96},
 year = 1996,
 isbn = {0-89791-794-4},
 location = {Montreal, Quebec, Canada},
 pages = {493--504},
 numpages = 12,
 doi = {10.1145/233269.233366},
 acmid = 233366,
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{Ronsse1999,
abstract = {This article presents a practical solution for the cyclic debugging of nondeterministic parallel programs. The solution consists of a combination of record/replay with automatic on-the-fly data race detection. This combination enables us to limit the record phase to the more efficient recording of the synchronization operations, while deferring the time-consuming data race detection to the replay phase. As the record phase is highly efficient, there is no need to switch it off, hereby eliminating the possibility of Heisenbugs because tracing can be left on all the time. This article describes an implementation of the tools needed to support RecPlay.},
author = {Ronsse, Michiel and {De Bosschere}, Koen},
doi = {10.1145/312203.312214},
issn = {07342071},
journal = {ACM Transactions on Computer Systems},
keywords = {D.1.3 [Programming Techniques]: Concurrent Programming - Parallel programming,D.2.5 [Software Engineering]: Testing and Debugging -Debugging aids,D.4.1 [Operating Systems]: Process Management - Concurrency,Deadlocks,Monitors,Tracing},
number = {2},
pages = {133--152},
title = {{RecPlay: A fully integrated practical record/replay system}},
volume = {17},
year = {1999}
}


@article{Gottlob2002,
abstract = {Several important decision problems on conjunctive queries (CQs) are NP-complete in general but become tractable, and actually highly parallelizable, if restricted to acyclic or nearly acyclic queries. Examples are the evaluation of Boolean CQs and query containment. These problems were shown tractable for conjunctive queries of bounded treewidth (Ch. Chekuri and A. Rajaraman, Theoret. Comput. Sci. 239 (2000), 211-229), and of bounded degree of cyclicity (M. Gyssens et al., Artif. Intell. 66 (1994), 57-89; M. Gyssens and J. Paredaens, in "Advances in Database Theory," Vol. 2, pp. 85-122, Plenum Press, New York, 1984). The so far most general concept of nearly acyclic queries was the notion of queries of bounded query-width introduced by Chekuri and Rajaraman (2000). While CQs of bounded query-width are tractable, it remained unclear whether such queries are efficiently recognizable. Chekuri and Rajaraman (2000) stated as an open problem whether for each constant k it can be determined in polynomial time if a query has query-width at most k. We give a negative answer by proving the NP-completeness of this problem (specifically, for k = 4). In order to circumvent this difficulty, we introduce the new concept of hypertree decomposition of a query and the corresponding notion of hypertree-width. We prove: (a) for each k, the class of queries with query-width bounded by k is properly contained in the class of queries whose hypertree-width is bounded by k; (b) unlike query-width, constant hypertree-width is efficiently recognizable; and (c) Boolean queries of bounded hypertree-width can be efficiently evaluated. {\textcopyright} 2002 Elsevier Science (USA).},
author = {Gottlob, Georg and Leone, Nicola and Scarcello, Francesco},
journal = {Journal of Computer and System Sciences},
month = {5},
number = {3},
pages = {579--627},
title = {{Hypertree Decompositions and Tractable Queries}},
volume = {64},
year = {2002}
}

@inproceedings{Barton2003,
abstract = {We present a streaming algorithm for evaluating XPath expressions that use backward axes (parent and ancestor) and forward axes in a single document-order traversal of an XML document. Other streaming XPath processors handle only forward axes. We show through experiments that our algorithm significantly outperforms (by more than a factor of two) a traditional non-streaming XPath engine. Furthermore, our algorithm scales better because it retains only the relevant portions of the input document in memory. Our engine successfully processes documents over 1GB in size, whereas the traditional XPath engine degrades considerably in performance for documents over 100 MB in size and fails to complete for documents of size over 200 MB.},
author = {Barton, Charles and Charles, Philippe and {Deepak Goyal} and {Mukund Raghavachari} and Fontoura, Marcus and Josifovski, Vanja},
booktitle = {Proceedings 19th International Conference on Data Engineering (Cat. No.03CH37405)},
pages = {455--466},
publisher = {IEEE},
title = {{Streaming XPath processing with forward and backward axes}},
year = {2003}
}

@inproceedings{Skoglund2004,
author = {Skoglund, Mats and Runeson, Per},
booktitle = {IEEE International Conference on Software Maintenance, ICSM},
doi = {10.1109/ICSM.2004.1357831},
isbn = {0-7695-2213-0},
issn = {1063-6773},
pages = {438--442},
title = {{A case study on regression test suite maintenance in system evolution}},
year = {2004}
}

@online{W3C2004,
url={https://www.w3.org/TR/DOM-Level-3-Core/introduction.html},
title={What is the Document Object Model?},
author={World Wide Web Consortium},
year={2004},
month={4},
addendum = {(accessed: 15.01.2021)}
}

@article{Anton2005,
abstract = {We introduce a wrapper induction algorithm for extracting information from tree-structured docu- ments like HTML or XML. It derives XPath- compatible extraction rules from a set of anno- tated example documents. The approach builds a minimally generalized tree traversal pattern, and augments it with conditions. Another variant se- lects a subset of conditions so that (a) the pattern is consistent with the training data, (b) the pat- tern's document coverage is minimized, and (c) conditions that match structures preceding the target nodes are preferred. We discuss the ro- bustness of rules induced by this selection strat- egy and we illustrate how these rules exhibit knowledge of the target concept.},
author = {Anton, Tobias},
journal = {LWA 2005 - Workshopwoche der GI-Fachgruppen/Arbeitskreise},
pages = {126--133},
title = {{XPath-Wrapper Induction by generalizing tree traversal patterns}},
year = {2005}
}

@article{Gottlob2005,
abstract = {We study the complexity of two central XML processing problems. The first is XPath 1.0 query processing, which has been shown to be in PTIME in previous work. We prove that both the data complexity and the query complexity of XPath 1.0 fall into lower (highly parallelizable) complexity classes, while the combined complexity is PTIME-hard. Subsequently, we study the sources of this hardness and identify a large and practically important fragment of XPath 1.0 for which the combined complexity is LOGCFL-complete and, therefore, in the highly parallelizable complexity class NC2. The second problem is the complexity of validating XML documents against various typing schemes like Document Type Definitions (DTDs), XML Schema Definitions (XSDs), and tree automata, both with respect to data and to combined complexity. For data complexity, we prove that validation is in LOGSPACE and depends crucially on how XML data is represented. For the combined complexity, we show that the complexity ranges from LOGSPACE to LOGCFL, depending on the typing scheme. {\textcopyright} 2005 ACM.},
author = {Gottlob, Georg and Koch, Christoph and Pichler, Reinhard and Segoufin, Luc},
journal = {Journal of the ACM},
keywords = {Complexity,DTD,LOGCFL,XML,XPath},
pages = {284--335},
title = {{The complexity of XPath query evaluation and XML typing}},
volume = {52},
year = {2005}
}

@article{Fluri2007,
author={B. Fluri and M. Wuersch and M. PInzger and H. Gall},
journal={IEEE Transactions on Software Engineering},
title={Change Distilling:Tree Differencing for Fine-Grained Source Code Change Extraction},
year=2007,
volume=33,
number=11,
pages={725-743},
keywords={software maintenance;software prototyping;tree data structures;minimum edit script;abstract syntax trees;software evolution analysis;fine-grained source code change extraction;change distilling tree differencing algorithm;Data mining;Taxonomy;Software maintenance;Programming profession;Software algorithms;Algorithm design and analysis;Software tools;Maintenance engineering;Software systems;History;Source code change extraction;tree differencing algorithms;software repositories;software evolution analysis},
doi={10.1109/TSE.2007.70731},
ISSN={0098-5589},
month={11},
}

@article{Memon2007,
abstract = {Graphical user interfaces (GUIs) are by far the most popular means used to interact with today's software. The functional correctness of a GUI is required to ensure the safety, robustness and usability of an entire software system. GUI testing techniques used in practice are resource intensive; model-based automated techniques are rarely employed. A key reason for the reluctance in the adoption of model-based solutions proposed by researchers is their limited applicability; moreover, the models are expensive to create. Over the past few years, the present author has been developing different models for various aspects ofGUI testing. This paper consolidates all of the models into one scalable event-flow model and outlines algorithms to semi-automatically reverse-engineer the model from an implementation. Earlier work on model-based test-case generation, test-oracle creation, coverage evaluation, and regression testing is recast in terms of this model by defining event-space exploration strategies (ESESs) and creating an end-to-end GUI testing process. Three such ESESs are described: for checking the event-flow model, test-case generation, and test- oracle creation. Two demonstrational scenarios show the application of the model and the three ESESs for experimentation and application in GUI testing.},
author = {Memon, Atif M.},
doi = {10.1002/stvr.364},
issn = {09600833},
journal = {Software Testing, Verification and Reliability},
keywords = {event-driven software,event-flow graph,event-flow model,graphical user interfaces,integration,model checking,test oracles,test-case generation,tree},
month = {9},
number = {3},
pages = {137--157},
pmid = {9189301},
title = {{An event-flow model of GUI-based applications for testing}},
volume = {17},
year = {2007}
}


@inproceedings{Tang2008,
abstract = {This paper presents an adaptive framework of keyword-driven automation testing to support the conversion of the keyword-based test cases into different kinds of test scripts automatically to be executed by different test applications under different test environments (such as GUI environment, database environment, etc.). XML is used to describe the keyword-based commands for the test case. An engine is provided in this framework to parse the XML file and dispatch the command sequences to the different test drivers according to the driver type pre-defined in the command. The test driver is responsible for dispatching the commands to the corresponding test applications to generate the test scripts automatically according to the keywords in the commands. The test scripts will be executed by the test applications on the system-under-test under different test environments. All the test results will be recorded into a log repository for generating all kinds of the test reports.},
author = {{Jingfan Tang} and {Xiaohua Cao} and Ma, Albert},
booktitle = {2008 IEEE International Conference on Automation and Logistics},
doi = {10.1109/ICAL.2008.4636415},
isbn = {978-1-4244-2502-0},
keywords = {Adaptive,Automation testing,Keyword driven},
month = {9},
pages = {1631--1636},
publisher = {IEEE},
title = {{Towards adaptive framework of keyword driven automation testing}},
year = {2008}
}

@article{Brooks2009,
abstract = {To date we have developed and applied numerous model-based GUI testing techniques; however, we are unable to provide definitive improvement schemes to real-world GUI test planners, as our data was derived from open source applications, small compared to industrial systems. This paper presents a study of three industrial GUI-based software systems developed at ABB, including data on classified defects detected during late-phase testing and customer usage, test suites, and source code change metrics. The results show that (1) 50\% of the defects found through the GUI are categorized as data access and handling, control flow and sequencing, correctness, and processing defects, (2) system crashes exposed defects 12-19\% of the time, and (3) GUI and non-GUI components are constructed differently, in terms of source code metrics.},
author = {Brooks, Penelope and Robinson, Brian and Memon, Atif M.},
doi = {10.1109/ICST.2009.11},
isbn = {9780769536019},
journal = {Proceedings - 2nd International Conference on Software Testing, Verification, and Validation, ICST 2009},
pages = {11--20},
publisher = {IEEE},
title = {{An initial characterization of industrial graphical user interface systems}},
year = {2009}
}


@inproceedings{Dalvi2009,
abstract = {On script-generated web sites, many documents share com- mon HTML tree structure, allowing wrappers to effectively extract information of interest. Of course, the scripts and thus the tree structure evolve over time, causing wrappers to break repeatedly, and resulting in a high cost of maintaining wrappers. In this paper, we explore a novel approach: we use temporal snapshots of web pages to develop a tree-edit model of HTML, and use this model to improve wrapper construction. We view the changes to the tree structure as suppositions of a series of edit operations: deleting nodes, inserting nodes and substituting labels of nodes. The tree structures evolve by choosing these edit operations stochas- tically. Our model is attractive in that the probability that a
source tree has evolved into a target tree can be estimated efficiently—in quadratic time in the size of the trees—making it a potentially useful tool for a variety of tree-evolution problems. We give an algorithm to learn the probabilistic model from training examples consisting of pairs of trees, and apply this algorithm to collections of web-page snap- shots to derive HTML-specific tree edit models. Finally, we describe a novel wrapper-construction framework that takes the tree-edit model into account, and compare the quality of resulting wrappers to that of traditional wrappers on syn- thetic and real HTML document examples.
Categories},
address = {New York, New York, USA},
author = {Dalvi, Nilesh and Bohannon, Philip and Sha, Fei},
booktitle = {Proceedings of the 35th SIGMOD international conference on Management of data - SIGMOD '09},
keywords = {all or part of,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,probabilistic tree-edit model,provided that copies are,this work for,wrappers,xpath},
pages = {335-347},
publisher = {ACM Press},
title = {{Robust web extraction}},
year = {2009}
}

@inproceedings{Grechanik2009,
abstract = {Since manual black-box testing of GUI-based APplications (GAPs) is tedious and laborious, test engineers create test scripts to automate the testing process. These test scripts interact with GAPs by performing actions on their GUI objects. As GAPs evolve, testers should fix their corresponding test scripts so that they can reuse them to test successive releases of GAPs. Currently, there are two main modes of maintaining test scripts: tool-based and manual. In practice, there is no consensus what approach testers should use to maintain test scripts. Test managers make their decisions ad hoc, based on their personal experience and perceived benefits of the tool-based approach versus the manual. In this paper we describe a case study with forty five professional programmers and test engineers to experimentally assess the tool-based approach for maintaining GUIdirected test scripts versus the manual approach. Based on the results of our case study and considering the high cost of the programmers' time and the lower cost of the time of test engineers, and considering that programmers often modify GAP objects in the process of developing software we recommend organizations to supply programmers with testing tools that enable them to fix test scripts faster so that these scripts can unit test software. The other side of our recommendation is that experienced test engineers are likely to be as productive with the manual approach as with the tool-based approach, and we consequently recommend that organizations do not need to provide each tester with an expensive tool license to fix test scripts.},
author = {Grechanik, Mark and Xie, Qing and Fu, Chen},
booktitle = {2009 IEEE International Conference on Software Maintenance},
doi = {10.1109/ICSM.2009.5306345},
isbn = {978-1-4244-4897-5},
issn = {1063-6773},
month = {9},
pages = {9--18},
publisher = {IEEE},
title = {{Experimental assessment of manual versus tool-based maintenance of GUI-directed test scripts}},
year = {2009}
}

@article{Roy2009,
abstract = {Over the last decade many techniques and tools for software clone detection have been proposed. In this paper, we provide a qualitative comparison and evaluation of the current state-of-the-art in clone detection techniques and tools, and organize the large amount of information into a coherent conceptual framework. We begin with background concepts, a generic clone detection process and an overall taxonomy of current techniques and tools. We then classify, compare and evaluate the techniques and tools in two different dimensions. First, we classify and compare approaches based on a number of facets, each of which has a set of (possibly overlapping) attributes. Second, we qualitatively evaluate the classified techniques and tools with respect to a taxonomy of editing scenarios designed to model the creation of Type-1, Type-2, Type-3 and Type-4 clones. Finally, we provide examples of how one might use the results of this study to choose the most appropriate clone detection tool or technique in the context of a particular set of goals and constraints. The primary contributions of this paper are: (1) a schema for classifying clone detection techniques and tools and a classification of current clone detectors based on this schema, and (2) a taxonomy of editing scenarios that produce different clone types and a qualitative evaluation of current clone detectors based on this taxonomy.},
author = {Roy, Chanchal K. and Cordy, James R. and Koschke, Rainer},
doi = {10.1016/j.scico.2009.02.007},
journal = {Science of Computer Programming},
keywords = {Clone detection,Comparison,Scenario-based evaluation,Software clone},
month = {5},
number = {7},
pages = {470--495},
publisher = {Elsevier B.V.},
title = {{Comparison and evaluation of code clone detection techniques and tools: A qualitative approach}},
volume = {74},
year = {2009}
}

@inproceedings{Shewchuk2010,
abstract = {Most of the modern software systems are being maintained and evolved through numerous versions. Thus, effective co-maintenance and co-evolution of their test suites along with their source code becomes an important and challenging issue. In this context, issues such as the types and extent of required maintenance activities on test suites, change in size/complexity, fault and cost effectiveness of multi-version functional test suites are among the most important issues. To study, analyze and get insights into co-maintenance and co-evolution of functional test suites with software systems w.r.t. the above issues, we have performed a case study on a functional GUI test suite of a popular open source project (jEdit). We chose as our test tool the IBM Rational Functional Tester, one of the leading commercial functional testing tools. The case study reveals interesting practical/empirical insights into the subject, e.g., developing a functional test suite in an earlier version and maintaining it might be a cost effective approach.},
address = {Redwood City, San Francisco Bay, CA, USA},
author = {Shewchuk, Yuri and Garousi, Vahid},
booktitle = {Proceedings of the 22nd International Conference on Software Engineering {\&} Knowledge Engineering (SEKE'2010)},
isbn = {1891706268},
keywords = {functional testing,evolution,test maintenance and,tool evaluation},
pages = {489--494},
title = {{Experience with Maintenance of a Functional GUI Test Suite using IBM Rational Functional Tester}},
year = {2010}
}

@inproceedings{Choudhary2011,
abstract = {Web applications tend to evolve quickly, resulting in errors and fail- ures in test automation scripts that exercise them. Repairing such scripts to work on the updated application is essential for maintain- ing the quality of the test suite. Updating such scripts manually is a time consuming task, which is often difficult and is prone to errors if not performed carefully. In this paper, we propose a tech- nique to automatically suggest repairs for such web application test scripts. Our technique is based on differential testing and compares the behavior of the test case on two successive versions of the web application: first version in which the test script runs successfully and the second version in which the script results in an error or fail- ure. By analyzing the difference between these two executions, our technique suggests repairs that can be applied to repair the scripts. To evaluate our technique, we implemented it in a tool calledWA- TER and exercised it on real web applications with test cases. Our experiments show thatWATER can suggest meaningful repairs for practical test cases, many of which correspond to those made later by developers themselves.},
address = {New York, New York, USA},
author = {Choudhary, Shauvik Roy and Zhao, Dan and Versee, Husayn and Orso, Alessandro},
booktitle = {Proceedings of the First International Workshop on End-to-End Test Script Engineering - ETSE '11},
keywords = {test repair, web testing},
pages = {24--29},
publisher = {ACM Press},
title = {{WATER}},
year = {2011}
}

@book{Goldstein2011,
title = {HTML5 \& CSS3 for the Real World},
author = {Goldstein, Alexis and Lazais, Louis and Weyl, Estelle},
year = {2011},
publisher = {Sitepoint}
}

@article{Montoto2011,
abstract = {Web automation applications are widely used for different purposes such as B2B integration, automated testing of web applications or technology and business watch. One crucial part in web automation applications is for them to easily generate and reproduce navigation sequences. This problem is specially complicated in the case of the new breed of AJAX-based websites. Although recently some tools have also addressed the problem, they show some limitations either in usability or their ability to deal with complex websites. In this paper, we propose a set of new techniques to build an automatic web navigation system able to deal with these complexities. Our main contributions are: a new method for recording navigation sequences able to scale to a wider range of events, an algorithm to identify in a change-resilient manner the target element of a user action, and a novel method to detect when the effects caused by a user action (including the effects of scripting code and AJAX requests) have finished. In addition, we have also tested our approach with a high number of real web sources and have compared it with other relevant web automation tools obtaining very good results. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Montoto, Paula and Pan, Alberto and Raposo, Juan and Bellas, Fernando and L{\'{o}}pez, Javier},
issn = {0169023X},
journal = {Data {\&} Knowledge Engineering},
keywords = {Web automation,Web integration,[28.8] Technologies of DBs/mediators and wrappers,[30.3] Web web-based information systems,[8.3] Data mining/web-based information},
month = {3},
pages = {269--283},
publisher = {Elsevier B.V.},
title = {{Automated browsing in AJAX websites}},
volume = {70},
year = {2011}
}

@inproceedings{Myers2008,
abstract = {Designers are skilled at sketching and prototyping the look of interfaces, but to explore various behaviors (what the interface does in response to input) typically requires programming using Javascript, ActionScript for Flash, or other languages. In our survey of 259 designers, 86\% reported that the behavior is more difficult to prototype than the appearance. Often (78\% of the time), designing the behavior requires collaborating with developers, but 76\% of designers reported that communicating the behavior to developers was more difficult than the appearance. Other results include that annotations such as arrows and paragraphs of text are used on top of sketches and storyboards to explain behaviors, and designers want to explore multiple versions of behaviors, but today's tools make this difficult. The results provide new ideas for future tools. {\textcopyright} 2008 IEEE.},
author = {Myers, Brad and Park, Sun Young and Nakano, Yoko and Mueller, Greg and Ko, Andrew},
booktitle = {2008 IEEE Symposium on Visual Languages and Human-Centric Computing},
doi = {10.1109/VLHCC.2008.4639081},
isbn = {978-1-4244-2528-0},
issn = {1943-6092},
month = {9},
pages = {177--184},
publisher = {IEEE},
title = {{How designers design and program interactive behaviors}},
year = {2008}
}

@inproceedings{Mesbah2009,
abstract = {AJAX-based Web 2.0 applications rely on stateful asynchronous client/server communication, and client-side runtime manipulation of the DOM tree. This not only makes them fundamentally different from traditional web applications, but also more error-prone and harder to test. We propose a method for testing AJAX applications automatically, based on a crawler to infer a flow graph for all (client-side) user interface states. We identify AJAX-specific faults that can occur in such states (related to DOM validity, error messages, discoverability, back-button compatibility, etc.) as well as DOM-tree invariants that can serve as oracle to detect such faults. We implemented our approach in ATUSA, a tool offering generic invariant checking components, a plugin-mechanism to add application-specific state validators, and generation of a test suite covering the paths obtained during crawling. We describe two case studies evaluating the fault revealing capabilities, scalability, required manual effort and level of automation of our approach. {\textcopyright} 2009 IEEE.},
author = {Mesbah, Ali and van Deursen, Arie},
booktitle = {2009 IEEE 31st International Conference on Software Engineering},
doi = {10.1109/ICSE.2009.5070522},
isbn = {978-1-4244-3453-4},
issn = {02705257},
pages = {210--220},
publisher = {IEEE},
title = {{Invariant-based automatic testing of AJAX user interfaces}},
year = {2009}
}

@inproceedings{Cunha2010,
abstract = {Nowadays, the usage of graphical user interfaces (GUIs) in order to ease the interaction with software applications is preferred over command line interfaces. Despite recent advances in software testing, GUIs are still tested in a complete ad-hoc, manual fashion, with little support from (industrial) testing tools. Automating the process of testing GUIs has additional challenges when compared to command-line applications. This paper presents an approach for GUI (semi-automated) testing which uses knowledge of the common behaviour of a GUI. To do so, the most common aspects in a GUI are identified and then a suite of test cases is automatically generated and executed. To validate our approach, we have run it against well known web-based applications, such as GMail. {\textcopyright} 2010 IEEE.},
author = {Cunha, Marco and Paiva, Ana C. R. and Ferreira, Hugo Sereno and Abreu, Rui},
booktitle = {2010 2nd International Conference on Software Technology and Engineering},
doi = {10.1109/ICSTE.2010.5608882},
isbn = {978-1-4244-8667-0},
keywords = {Graphical user interfaces,Patterns,Software testing},
month = {10},
pages = {202--206},
publisher = {IEEE},
title = {{PETTool: A pattern-based GUI testing tool}},
volume = {1},
year = {2010}
}


@incollection{Memon2010,
abstract = {Despite the ubiquity of software applications that employ a graphical-user interface (GUI) front-end, functional system testing of these applications has remained, until recently, an understudied research area. During “GUI testing,” test cases, modeled as sequences of user input events, are created and executed on the software by exercising the GUI's widgets. Because each possible sequence of user events may potentially be a test case and today's GUIs offer enormous flexibility to end-users, in principle, GUI testing requires a prohibitively large number of test cases. Any practical test-case generation technique must sample the vast GUI input space. Existing techniques are largely manual, and hence extremely resource intensive. Several new automated model-based techniques have been developed in the past decade. All these techniques develop, either manually or automatically, a model of the GUI and employ it to generate test cases. This chapter presents the first detailed taxonomy of these techniques. A small GUI application is used as a running example to demonstrate each technique and illustrate its relative strengths and weaknesses. {\textcopyright} 2010 Elsevier Inc.},
author = {Memon, Atif M. and Nguyen, Bao N.},
booktitle = {Advances in Computers},
doi = {10.1016/S0065-2458(10)80003-8},
edition = {1},
issn = {00652458},
pages = {121--162},
publisher = {Elsevier Inc.},
title = {{Advances in Automated Model-Based System Testing of Software Applications with a GUI Front-End}},
volume = {80},
year = {2010}
}


@inproceedings{Gupta2011,
abstract = {Applications, once developed, need to be maintained and tested as they undergo frequent changes. Test automation plays a significant role in testing activity, as it saves time and provides better utilization of resources. Test automation itself comes with many challenges such as mapping of user specifications to test-cases, test-case generation, maintenance of test-cases and test-scripts. In this paper, we propose a model-driven approach for test automation to provide end-to-end assistance in test case generation and automation, with focus on re-usability and maintainability. Functional specifications of system are mapped to test-cases for traceability which ensures better test automation process. Functional specifications of system are used as an input to design process models, which are used for automatic generation of test-cases. Process models consist of flows of different tasks in specified sequence. By recording the individual tasks, test-scripts for all the test-cases are generated. The test-cases and test-scripts can be modified and maintained using user friendly user-interface (UI) to provide better control to test designer and ease the load of tester. In this paper, we also present a case study performed on JBilling application [18] to evaluate our approach.},
address = {New York, New York, USA},
author = {Gupta, Priya and Surve, Prafullakumar},
booktitle = {Proceedings of the First International Workshop on End-to-End Test Script Engineering - ETSE '11},
doi = {10.1145/2002931.2002932},
isbn = {9781450308083},
keywords = {model based approach,test case maintenance,test execution,test scripts,test-automation,test-case generation},
pages = {1--7},
publisher = {ACM Press},
title = {{Model based approach to assist test case creation, execution, and maintenance for test automation}},
year = {2011}
}


@article{Zaidman2011,
abstract = {Many software production processes advocate rigorous development testing alongside functional code writing, which implies that both test code and production code should co-evolve. To gain insight in the nature of this co-evolution, this paper proposes three views (realized by a tool called TeMo) that combine information from a software project's versioning system, the size of the various artifacts and the test coverage reports. We validate these views against two open source and one industrial software project and evaluate our results both with the help of log messages, code inspections and the original developers of the software system. With these views we could recognize different co-evolution scenarios (i.e., synchronous and phased) and make relevant observations for both developers as well as test engineers.},
author = {Zaidman, Andy and {Van Rompaey}, Bart and van Deursen, Arie and Demeyer, Serge},
doi = {10.1007/s10664-010-9143-7},
issn = {1382-3256},
journal = {Empirical Software Engineering},
keywords = {Co-evolution,Software evolution,Software repository mining,Software testing,Test coverage},
month = {6},
number = {3},
pages = {325--364},
title = {{Studying the co-evolution of production and test code in open source and industrial developer test processes through repository mining}},
volume = {16},
year = {2011}
}

@inproceedings{Hametner2012,
abstract = {In the field of industrial automation systems software becomes an important factor because engineers tend to move the realization of functional requirements from hardware to software components. The main reason for this is that software components allow increasing product flexibility. As a consequence software complexity increases rapidly and requires systematic, automation-supported and agile testing approaches. Thus, systematic and agile testing are key challenges in industrial control software development to ensure and improve systems quality. Further different implementation standards, i.e., IEC 61131-3 and IEC 61499, arise additional challenges in constructing and testing industrial automation systems software. This paper presents an agile and keyword-driven test approach with focus on testing implementations based on both important industrial standards and illustrates the applicability of the purposed approach in a sample implementation, i.e., a High Speed Pick and Place unit. Main results show the applicability of keyword-driven testing based on a defined subset of keywords (common for IEC 61131-3 and IEC 61499) and thus enable agile and automation-supported testing more effective and efficient. {\textcopyright} 2012 IEEE.},
author = {Hametner, Reinhard and Winkler, Dietmar and Zoitl, Alois},
booktitle = {IECON 2012 - 38th Annual Conference on IEEE Industrial Electronics Society},
doi = {10.1109/IECON.2012.6389298},
isbn = {978-1-4673-2421-2},
keywords = {IEC 61131-3,IEC 61499,Industrial Control Applications,Keyword-driven Test,Test Automation},
month = {10},
pages = {3727--3732},
publisher = {IEEE},
title = {{Agile testing concepts based on keyword-driven testing for industrial automation systems}},
year = {2012}
}


@inproceedings{Issa2012,
abstract = {Graphical User Interface (GUI) testing literature emphasizes testing a system's functionality through its GUI, rather than testing visual aspects of the GUI itself. In this paper we introduce the notion of visual testing as a subset of GUI testing. To explore visual testing, we have conducted a study of defects in four open source systems. We found that visual defects represent between 16\% and 33\% of reported defects in those systems. Two categories of visual defects are identified with six subcategories within each of them. Other findings are also reported that are aimed at motivating the importance and the need for systematically conducting visual testing among researchers and practitioners. {\textcopyright} 2012 IEEE.},
author = {Issa, Ayman and Sillito, Jonathan and Garousi, Vahid},
booktitle = {Proceedings of IEEE International Symposium on Web Systems Evolution, WSE},
doi = {10.1109/WSE.2012.6320526},
isbn = {9781467330558},
issn = {21606153},
keywords = {graphical user interface,visual defect,visual testing},
pages = {11--15},
publisher = {IEEE},
title = {{Visual testing of Graphical User Interfaces: An exploratory study towards systematic definitions and approaches}},
year = {2012}
}

@article{Mesbah2012,
abstract = {Ajax-based Web 2.0 applications rely on stateful asynchronous client/server communication, and client-side runtime manipulation of the DOM tree. This not only makes them fundamentally different from traditional web applications, but also more error-prone and harder to test. We propose a method for testing Ajax applications automatically, based on a crawler to infer a state-flow graph for all (client-side) user interface states. We identify Ajax-specific faults that can occur in such states (related to, e.g., DOM validity, error messages, discoverability, back-button compatibility) as well as DOM-tree invariants that can serve as oracles to detect such faults. Our approach, called Atusa, is implemented in a tool offering generic invariant checking components, a plugin-mechanism to add application-specific state validators, and generation of a test suite covering the paths obtained during crawling. We describe three case studies, consisting of six subjects, evaluating the type of invariants that can be obtained for Ajax applications as well as the fault revealing capabilities, scalability, required manual effort, and level of automation of our testing approach.},
author = {Mesbah, Ali and van Deursen, A. and Roest, Danny},
doi = {10.1109/TSE.2011.28},
isbn = {9781424434527},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Ajax,Automated testing,web applications},
month = {1},
number = {1},
pages = {35--53},
title = {{Invariant-Based Automatic Testing of Modern Web Applications}},
volume = {38},
year = {2012}
}


@article{Pinto2012,
abstract = {Test suites, once created, rarely remain static. Just like the application they are testing, they evolve throughout their lifetime. Test obsolescence is probably the most known reason for test-suite evolution---test cases cease to work because of changes in the code and must be suitably repaired. Repairing existing test cases manually, however, can be extremely time consuming, especially for large test suites, which has motivated the recent development of automated test-repair techniques. We believe that, for developing effective repair techniques that are applicable in real-world scenarios, a fundamental prerequisite is a thorough understanding of how test cases evolve in practice. Without such knowledge, we risk to develop techniques that may work well for only a small number of tests or, worse, that may not work at all in most realistic cases. Unfortunately, to date there are no studies in the literature that investigate how test suites evolve. To tackle this problem, in this paper we present a technique for studying test-suite evolution, a tool that implements the technique, and an extensive empirical study in which we used our technique to study many versions of six real-world programs and their unit test suites. This is the first study of this kind, and our results reveal several interesting aspects of test-suite evolution. In particular, our findings show that test repair is just one possible reason for test-suite evolution, whereas most changes involve refactorings, deletions, and additions of test cases. Our results also show that test modifications tend to involve complex, and hard-to-automate, changes to test cases, and that existing test-repair techniques that focus exclusively on assertions may have limited practical applicability. More generally, our findings provide initial insight on how test cases are added, removed, and modified in practice, and can guide future research efforts in the area of test-suite evolution.},
author = {Pinto, Leandro Sales and Sinha, Saurabh and Orso, Alessandro},
doi = {10.1145/2393596.2393634},
isbn = {978-1-4503-1614-9},
journal = {Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
keywords = {test-suite evolution,test-suite maintenance,unit testing},
pages = {33:1--33:11},
title = {{Understanding Myths and Realities of Test-suite Evolution}},
volume = {1},
year = {2012}
}

@article{Utting2012,
abstract = {Model-based testing (MBT) relies on models of a system under test and/or its environment to derive test cases for the system. This paper discusses the process of MBT and defines a taxonomy that covers the key aspects of MBT approaches. It is intended to help with understanding the characteristics, similarities and differences of those approaches, and with classifying the approach used in a particular MBT tool. To illustrate the taxonomy, a description of how three different examples of MBT tools fit into the taxonomy is provided.},
author = {Utting, Mark and Pretschner, Alexander and Legeard, Bruno},
doi = {10.1002/stvr.456},
issn = {09600833},
journal = {Software Testing, Verification and Reliability},
keywords = {clustering,inheritance metrics,machine learning,object oriented paradigm,prediction,software fault,unsupervised learning},
month = {8},
number = {5},
pages = {297--312},
title = {{A taxonomy of model-based testing approaches}},
volume = {22},
year = {2012}
}

@inproceedings{Alegroth2013,
author = {Alegroth, Emil and Feldt, Robert and Olsson, Helena H},
booktitle = {2013 IEEE Sixth International Conference on Software Testing, Verification and Validation},
doi = {10.1109/ICST.2013.14},
isbn = {978-0-7695-4968-2},
keywords = {-visual gui testing,company saab ab,empirical,entirely by industrial practitioners,industrial case study,into vgt at the,nance,subdivision security and,test automation,test mainte-,transition,with the goal to},
month = {3},
pages = {56--65},
publisher = {IEEE},
title = {{Transitioning Manual System Test Suites to Automated Testing: An Industrial Case Study}},
year = {2013}
}

@article{Banerjee2013,
abstract = {Context GUI testing is system testing of a software that has a graphical-user interface (GUI) front-end. Because system testing entails that the entire software system, including the user interface, be tested as a whole, during GUI testing, test cases - modeled as sequences of user input events - are developed and executed on the software by exercising the GUI's widgets (e.g., text boxes and clickable buttons). More than 230 articles have appeared in the area of GUI testing since 1991. Objective In this paper, we study this existing body of knowledge using a systematic mapping (SM). Method The SM is conducted using the guidelines proposed by Petersen et al. We pose three sets of research questions. We define selection and exclusion criteria. From the initial pool of 230 articles, published in years 1991-2011, our final pool consisted of 136 articles. We systematically develop a classification scheme and map the selected articles to this scheme. Results We present two types of results. First, we report the demographics and bibliometrics trends in this domain, including: top-cited articles, active researchers, top venues, and active countries in this research area. Moreover, we derive the trends, for instance, in terms of types of articles, sources of information to derive test cases, types of evaluations used in articles, etc. Our second major result is a publicly-accessible repository that contains all our mapping data. We plan to update this repository on a regular basis, making it a "live" resource for all researchers. Conclusion Our SM provides an overview of existing GUI testing approaches and helps spot areas in the field that require more attention from the research community. For example, much work is needed to connect academic model-based techniques with commercially available tools. To this end, studies are needed to compare the state-of-the-art in GUI testing in academic techniques and industrial tools. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Banerjee, Ishan and Nguyen, Bao and Garousi, Vahid and Memon, Atif},
doi = {10.1016/j.infsof.2013.03.004},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Bibliometrics,GUI application,Paper repository,Systematic mapping,Testing},
month = {10},
number = {10},
pages = {1679--1694},
publisher = {Elsevier B.V.},
title = {{Graphical user interface (GUI) testing: Systematic mapping and repository}},
volume = {55},
year = {2013}
}


@article{Kan2013,
abstract = {Through reusing software test components, automated software testing generally costs less than manual software testing. There has been much research on how to develop the reusable test components, but few fall on how to estimate the reusability of test components for automated testing. The purpose of this paper is to present a method of minimum reusability estimation for automated testing based on the return on investment (ROI) model. Minimum reusability is a benchmark for the whole automated testing process. If the reusability in one test execution is less than the minimum reusability, some new strategies must be adopted in the next test execution to increase the reusability. Only by this way, we can reduce unnecessary costs and finally get a return on the investment of automated testing. {\textcopyright} 2013 Shanghai Jiaotong University and Springer-Verlag Berlin Heidelberg.},
author = {Kan, Hong Xing and Wang, Guo Qiang and Wang, Zong Dian and Ding, Shuai},
doi = {10.1007/s12204-013-1406-1},
issn = {10071172},
journal = {Journal of Shanghai Jiaotong University (Science)},
keywords = {automated software testing,manual software testing,mean maintenance costs multiplier,minimum reusability estimation,reusable software test components,threshold},
number = {3},
pages = {360--365},
title = {{A method of minimum reusability estimation for automated software testing}},
volume = {18},
year = {2013}
}

@inproceedings{Leotta2013,
abstract = {There are several approaches for automated func- tional web testing and the choice among them depends on a number of factors, including the tools used for web testing and the costs associated with their adoption. In this paper, we present an empirical cost/benefit analysis of two different categories of automated functional web testing approaches: (1) capture- replay web testing (in particular, using Selenium IDE); and, (2) programmable web testing (using Selenium WebDriver). On a set of six web applications, we evaluated the costs of applying these testing approaches both when developing the initial test suites from scratch and when the test suites are maintained, upon the release of a new software version. Results indicate that, on the one hand, the development of the test suites is more expensive in terms of time required (between 32{\%} and 112{\%}) when the programmable web testing approach is adopted, but on the other hand, test suite maintenance is less expensive when this approach is used (with a saving between 16{\%} and 51{\%}). We found that, in the majority of the cases, after a small number of releases (from one to three), the cumulative cost of programmable web testing becomes lower than the cost involved with capture-replay web testing and the cost saving gets amplified over the successive releases. Index Terms—Test Case Evolution, Test Case Repair, Empiri- cal Study, Selenium IDE, Selenium WebDriver.},
author = {Leotta, Maurizio and Clerissi, Diego and Ricca, Filippo and Tonella, Paolo},
booktitle = {2013 20th Working Conference on Reverse Engineering (WCRE)},
keywords = {Empirirical Study, Selenium IDE, Selenium WebDriver, Test Case Evolution, Test Case Repair},
month = {10},
pages = {272--281},
publisher = {IEEE},
title = {{Capture-replay vs. programmable web testing: An empirical assessment during test case evolution}},
year = {2013}
}

@inproceedings{Gomez2013,
abstract = {Touchscreen-based devices such as smartphones and tablets are gaining popularity, but their rich input capabilities pose new development and testing complications. To alleviate this problem, we present an approach and tool named Reran that permits record-and-replay for the Android smartphone platform. Existing GUI-level record-and-replay approaches are inadequate due to the expressiveness of the smartphone domain, in which applications support sophisticated GUI gestures, depend on inputs from a variety of sensors on the device, and have precise timing requirements among the various input events. We address these challenges by directly capturing the low-level event stream on the phone, which includes both GUI events and sensor events, and replaying it with microsecond accuracy. Moreover, Reran does not require access to app source code, perform any app rewriting, or perform any modifications to the virtual machine or Android platform. We demonstrate RERAN's applicability in a variety of scenarios, including (a) replaying 86 out of the Top-100 Android apps on Google Play; (b) reproducing bugs in popular apps, e.g., Firefox, Facebook, Quickoffice; and (c) fast-forwarding executions. We believe that our versatile approach can help both Android developers and researchers. {\textcopyright} 2013 IEEE.},
author = {Gomez, Lorenzo and Neamtiu, Iulian and Azim, Tanzirul and Millstein, Todd},
booktitle = {2013 35th International Conference on Software Engineering (ICSE)},
doi = {10.1109/ICSE.2013.6606553},
isbn = {978-1-4673-3076-3},
issn = {02705257},
keywords = {Google Android,Record-and-replay},
month = {5},
pages = {72--81},
publisher = {IEEE},
title = {{RERAN: Timing- and touch-sensitive record and replay for Android}},
url = {http://ieeexplore.ieee.org/document/6606553/},
year = {2013}
}


@inproceedings{Machiry2013,
abstract = {We present a system Dynodroid for generating relevant inputs to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all, Dynodroid monitors the reaction of an app upon each event in a lightweight manner, using it to guide the generation of the next event to the app. Dynodroid also allows interleaving events from machines, which are better at generating a large number of simple inputs, with events from humans, who are better at providing intelligent inputs. We evaluated Dynodroid on 50 open-source Android apps, and compared it with two prevalent approaches: users manually exercising apps, and Monkey, a popular fuzzing tool. Dynodroid, humans, and Monkey covered 55\%, 60\%, and 53\%, respectively, of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps, and 6 bugs in 5 of the top 1, 000 free apps on Google Play. Copyright 2013 ACM.},
address = {New York, New York, USA},
author = {Machiry, Aravind and Tahiliani, Rohan and Naik, Mayur},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2013},
doi = {10.1145/2491411.2491450},
isbn = {9781450322379},
keywords = {Android,GUI testing,Testing event-driven programs},
pages = {224},
publisher = {ACM Press},
title = {{Dynodroid: an input generation system for Android apps}},
year = {2013}
}


@article{Rattan2013,
title = "Software clone detection: A systematic review ",
journal = "Inf. Softw. Tech. ",
volume = 55,
number = 7,
pages = "1165 - 1199",
year = 2013,
issn = "0950-5849",
doi = "10.1016/j.infsof.2013.01.008",
author = "Dhavleesh Rattan and Rajesh Bhatia and Maninder Singh",
keywords = {"Software clone",  "Clone detection", "Systematic literature review", "Semantic clones", "Model based clone "}
}

@inproceedings{Thummalapenta2013,
abstract = {Test automation, which involves the conversion of manual test cases to executable test scripts, is necessary to carry out efficient regression testing of GUI-based applications. However, test automation takes significant investment of time and skilled effort. Moreover, it is not a one-time investment: as the application or its environment evolves, test scripts demand continuous patching. Thus, it is challenging to perform test automation in a cost-effective manner. At IBM, we developed a tool, called ATA [1], [2], to meet this challenge. ATA has novel features that are designed to lower the cost of initia test automation significantly. Moreover, ATA has the ability to patch scripts automatically for certain types of application or environment changes. How well does ATA meet its objectives in the real world? In this paper, we present a detailed case study in the context of a challenging production environment: an enterprise web application that has over 6500 manual test cases, comes in two variants, evolves frequently, and needs to be tested on multiple browsers in time-constrained and resource-constrained regression cycles. We measured how well ATA improved the efficiency in initial automation. We also evaluated the effectiveness of ATA's change-resilience along multiple dimensions: application versions, browsers, and browser versions. Our study highlights several lessons for test-automation practitioners as well as open research problems in test automation.},
address = {San Francisco, CA, USA},
author = {Thummalapenta, Suresh and Devaki, Pranavadatta and Sinha, Saurabh and Chandra, Satish and Gnanasundaram, Sivagami and Nagaraj, Deepa D. and Kumar, Sampath and Kumar, Sathish},
booktitle = {2013 35th International Conference on Software Engineering (ICSE)},
month = {5},
pages = {1002--1011},
publisher = {IEEE},
title = {{Efficient and change-resilient test automation: An industrial case study}},
year = {2013}
}

@book{Bosch2014,
abstract = {This book provides essential insights on the adoption of modern software engineering practices at large companies producing software-intensive systems, where hundreds or even thousands of engineers collaborate to deliver on new systems and new versions of already deployed ones. It is based on the findings collected and lessons learned at the Software Center (SC), a unique collaboration between research and industry, with Chalmers University of Technology, Gothenburg University and Malm{\"{o}} University as academic partners and Ericsson, AB Volvo, Volvo Car Corporation, Saab Electronic Defense Systems, Grundfos, Axis Communications, Jeppesen (Boeing) and Sony Mobile as industrial partners. The 17 chapters present the "Stairway to Heaven" model, which represents the typical evolution path companies move through as they develop and mature their software engineering capabilities. The chapters describe theoretical frameworks, conceptual models and, most importantly, the industrial experiences gained by the partner companies in applying novel software engineering techniques. The book's structure consists of six parts. Part I describes the model in detail and presents an overview of lessons learned in the collaboration between industry and academia. Part II deals with the first step of the Stairway to Heaven, in which R{\&}D adopts agile work practices. Part III of the book combines the next two phases, i.e., continuous integration (CI) and continuous delivery (CD), as they are closely intertwined. Part IV is concerned with the highest level, referred to as "R{\&}D as an innovation system," while Part V addresses a topic that is separate from the Stairway to Heaven and yet critically important in large organizations: organizational performance metrics that capture data, and visualizations of the status of software assets, defects and teams. Lastly, Part VI presents the perspectives of two of the SC partner companies. The book is intended for practitioners and professionals in the software-intensive systems industry, providing concrete models, frameworks and case studies that show the specific challenges that the partner companies encountered, their approaches to overcoming them, and the results. Researchers will gain valuable insights on the problems faced by large software companies, and on how to effectively tackle them in the context of successful cooperation projects.},
author = {Bosch, Jan},
booktitle = {Continuous software engineering},
pages = {1--226},
publisher = {Springer International Publishing},
title = {{Continuous Software Engineering}},
year = {2014}
}

@inproceedings{Christophe2014,
abstract = {Functional testing requires executing particular sequences of user actions. Test automation tools enable scripting user actions such that they can be repeated more easily. SELENIUM, for instance, enables testing web applications through scripts that interact with a web browser and assert properties about its observable state. However, little is known about how common such tests are in practice. We therefore present a cross-sectional quantitative study of the prevalence of SELENIUM-based tests among open-source web applications, and of the extent to which such tests are used within individual applications. Automating functional tests also brings about the problem of maintaining test scripts. As the system under test evolves, its test scripts are bound to break. Even less is known about the way test scripts change over time. We therefore also present a longitudinal quantitative study of whether and for how long test scripts are maintained, as well as a longitudinal qualitative study of the kind of changes they undergo. To the former's end, we propose two new metrics based on whether a commit to the application's version repository touches a test file. To the latter's end, we propose to categorize the changes within each commit based on the elements of the test upon which they operate. As such, we are able to identify the elements of a test that are most prone to change.},
author = {Christophe, Laurent and Stevens, Reinout and {De Roover}, Coen and {De Meuter}, Wolfgang},
booktitle = {2014 IEEE International Conference on Software Maintenance and Evolution},
keywords = {Functional testing,Selenium,Test automation},
month = {9},
pages = {141--150},
publisher = {IEEE},
title = {{Prevalence and Maintenance of Automated Functional Tests for Web Applications}},
year = {2014}
}

@inproceedings{Falleri2014,
address = {New York, New York, USA},
author = {Falleri, Jean-R{\'{e}}my and Morandat, Flor{\'{e}}al and Blanc, Xavier
and Martinez, Matias and Monperrus, Martin},
booktitle = {Proceedings of the 29th ACM/IEEE international conference on
Automated software engineering - ASE '14},
doi = {10.1145/2642937.2642982},
isbn = {9781450330138},
keywords = {ast,program comprehension,software evolution,tree differencing},
pages = {313--324},
publisher = {ACM Press},
title = {{Fine-grained and accurate source code differencing}},
year = {2014}
}

@inproceedings{Leotta2014,
abstract = {In the context of web regression testing, the main aging factor for a test suite is related to the continuous evolution of the underlying web application that makes the test cases broken. This rapid decay forces the quality experts to evolve the test ware. One of the major costs of test case evolution is due to the manual effort necessary to repair broken web page element locators. Locators are lines of source code identifying the web elements the test cases interact with. Web test cases rely heavily on locators, for instance to identify and fill the input portions of a web page (e.g., The form fields), to execute some computations (e.g., By locating and clicking on buttons) and to verify the correctness of the output (by locating the web page elements showing the results). In this paper we present ROBULA (ROBUst Locator Algorithm), a novel algorithm able to partially prevent and thus reduce the aging of web test cases by automatically generating robust XPath-based locators that are likely to work also when new releases of the web application are created. Preliminary results show that XPath locators produced by ROBULA are substantially more robust than absolute and relative locators, generated by state of the practice tools such as Fire Path. Fragility of the test suites is reduced on average by 56{\%} for absolute locators and 41{\%} for relative locators.},
author = {Leotta, Maurizio and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
booktitle = {2014 IEEE International Symposium on Software Reliability Engineering Workshops},
keywords = {Robust locators,Test cases aging,Web testing},
month = {11},
pages = {449--454},
publisher = {IEEE},
title = {{Reducing Web Test Cases Aging by Means of Robust XPath Locators}},
year = {2014}
}

@inproceedings{Mahmood2014,
abstract = {Proliferation of Android devices and apps has created a demand for applicable automated software testing techniques. Prior research has primarily focused on either unit or GUI testing of Android apps, but not their end-to-end system testing in a systematic manner. We present EvoDroid, an evolutionary approach for system testing of Android apps. EvoDroid overcomes a key shortcoming of using evolutionary techniques for system testing, i.e., the inability to pass on genetic makeup of good individuals in the search. To that end, EvoDroid combines two novel techniques: (1) an Android-specific program analysis technique that identifies the segments of the code amenable to be searched independently, and (2) an evolutionary algorithm that given information of such segments performs a step- wise search for test cases reaching deep into the code. Our experi- ments have corroborated EvoDroid's ability to achieve significantly higher code coverage than existing Android testing tools.},
address = {New York, New York, USA},
author = {Mahmood, Riyadh and Mirzaei, Nariman and Malek, Sam},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering - FSE 2014},
doi = {10.1145/2635868.2635896},
isbn = {9781450330565},
keywords = {android,evolutionary testing,program analysis},
pages = {599--609},
publisher = {ACM Press},
title = {{EvoDroid: segmented evolutionary testing of Android apps}},
year = {2014}
}


@article{Nguyen2014,
abstract = {Most of today's software applications feature a graphical user interface (GUI) front-end. System testing of these applications requires that test cases, mod- eled as sequences of GUI events, be generated and executed on the software. We term GUI testing as the process of testing a software application through its GUI. Re- searchers and practitioners agree that one must employ a variety of techniques (e.g., model-based, capture/replay, manually scripted) for effective GUI testing. Yet, the tools available today for GUI testing are limited in the techniques they support. In this paper, we describe an innovative tool called GUITAR that supports a wide va- riety of GUI testing techniques. The innovation lies in the architecture of GUITAR, which uses plug-ins to support flexibility and extensibility. Software developers and quality assurance engineers may use this architecture to create new toolchains, new workflows based on the toolchains, and plug in a variety of measurement tools to conduct GUI testing.We demonstrate these features of GUITAR via several carefully crafted case studies.},
author = {Nguyen, Bao N. and Robbins, Bryan and Banerjee, Ishan and Memon, Atif},
doi = {10.1007/s10515-013-0128-9},
issn = {0928-8910},
journal = {Automated Software Engineering},
keywords = {GUI testing,Test automation,Test generation},
month = {3},
number = {1},
pages = {65--105},
title = {{GUITAR: an innovative tool for automated testing of GUI-driven software}},
volume = {21},
year = {2014}
}


@online{W3C2014,
url={https://www.w3.org/WAI/GL/wiki/Using_ARIA_landmarks_to_identify_regions_of_a_page},
title={Using ARIA landmarks to identify regions of a page},
author={World Wide Web Consortium},
year={2014},
month={1},
urldate={2021-01-16}
}

@article{Yandrapally2014,
abstract = {Despite the seemingly obvious advantage of test automation, significant skepticism exists in the industry regarding its cost-benefit tradeoffs. Test scripts for web applications are fragile: even small changes in the page layout can break a number of tests, requiring the expense of re-automating them. Moreover, a test script created for one browser cannot be relied upon to run on a different web browser: it requires duplicate effort to create and maintain versions of tests for a variety of browsers. Because of these hidden costs, organizations often fall back to manual testing. We present a fresh solution to the problem of test-script fragility. Often, the root cause of test-script fragility is that, to identify UI elements on a page, tools typically record some metadata that depends on the internal representation of the page in a browser. Our technique eliminates metadata almost entirely. Instead, it identifies UI elements relative to other prominent elements on the page. The core of our technique automatically identifies a series of contextual clues that unambiguously identify a UI element, without recording anything about the internal representation. Empirical evidence shows that our technique is highly accurate in computing contextual clues, and outperforms existing techniques in its resilience to UI changes as well as browser changes.},
author = {Yandrapally, Rahulkrishna and Thummalapenta, Suresh and Sinha, Saurabh and Chandra, Satish},
journal = {2014 International Symposium on Software Testing and Analysis, ISSTA 2014 - Proceedings},
keywords = {GUI test automation,Test-script fragility},
pages = {304--314},
title = {{Robust test automation using contextual clues}},
year = {2014}
}

@article{Zanoni2014,
author = {Zanoni, Marco and Perin, Fabrizio and Fontana, Francesca Arcelli and Viscusi, Gianluigi},
title = {Pattern detection for conceptual schema recovery in data-intensive systems},
journal = {Journal of Software: Evolution and Process},
volume = {26},
number = {12},
pages = {1172-1192},
keywords = {conceptual schema, design pattern detection, object-relational mapping, reverse engineering},
doi = {https://doi.org/10.1002/smr.1656},
abstract = {ABSTRACT In this paper, an approach for information systems reverse engineering is proposed and applied. The aim is to support a unified perspective to the reverse engineering process of both data and software. At the state of the art, indeed, many methods, techniques, and tools for software reverse engineering have been proposed to support program comprehension, software maintenance, and software evolution. Other approaches and tools have been proposed for data reverse engineering, with the aim, for example, to provide complete and up-to-date documentation of legacy databases. However, the two engineering communities often worked independently, and very few approaches addressed the reverse engineering of both data and software as information system's constituencies. Hence, a higher integration is needed to support a better co-evolution of databases and programs, in an environment often characterized by high availability of data and volatility of information flows. Accordingly, the approach we propose leverages the detection of object-relational mapping design patterns to build a conceptual schema of the software under analysis. Then, the conceptual schema is mapped to the domain model of the system, to support the design of the evolution of the information system itself. The approach is evaluated on two large-scale open-source enterprise applications. Copyright © 2014 John Wiley \& Sons, Ltd.},
year = {2014}
}


@article{Alegroth2015,
abstract = {In today's software development industry, high-level tests such as Graphical User Interface (GUI) based system and acceptance tests are mostly performed with manual practices that are often costly, tedious and error prone. Test automation has been proposed to solve these problems but most automation techniques approach testing from a lower level of system abstraction. Their suitability for high-level tests has therefore been questioned. High-level test automation techniques such as Record and Replay exist, but studies suggest that these techniques suffer from limitations, e.g. sensitivity to GUI layout or code changes, system implementation dependencies, etc. Visual GUI Testing (VGT) is an emerging technique in industrial practice with perceived higher flexibility and robustness to certain GUI changes than previous high-level (GUI) test automation techniques. The core of VGT is image recognition which is applied to analyze and interact with the bitmap layer of a system's front end. By coupling image recognition with test scripts, VGT tools can emulate end user behavior on almost any GUI-based system, regardless of implementation language, operating system or platform. However, VGT is not without its own challenges, problems and limitations (CPLs) but, like for many other automated test techniques, there is a lack of empirically-based knowledge of these CPLs and how they impact industrial applicability. Crucially, there is also a lack of information on the cost of applying this type of test automation in industry. This manuscript reports an empirical, multi-unit case study performed at two Swedish companies that develop safety-critical software. It studies their transition from manual system test cases into tests automated with VGT. In total, four different test suites that together include more than 300 high-level system test cases were automated for two multi-million lines of code systems. The results show that the transitioned test cases could find defects in the tested systems and that all applicable test cases could be automated. However, during these transition projects a number of hurdles had to be addressed; a total of 58 different CPLs were identified and then categorized into 26 types. We present these CPL types and an analysis of the implications for the transition to and use of VGT in industrial software development practice. In addition, four high-level solutions are presented that were identified during the study, which would address about half of the identified CPLs. Furthermore, collected metrics on cost and return on investment of the VGT transition are reported together with information about the VGT suites' defect finding ability. Nine of the identified defects are reported, 5 of which were unknown to testers with extensive experience from using the manual test suites. The main conclusion from this study is that even though there are many challenges related to the transition and usage of VGT, the technique is still valuable, flexible and considered cost-effective by the industrial practitioners. The presented CPLs also provide decision support in the use and advancement of VGT and potentially other automated testing techniques similar to VGT, e.g. Record and Replay.},
author = {Al{\'{e}}groth, Emil and Feldt, Robert and Ryrholm, Lisa},
journal = {Empirical Software Engineering},
keywords = {Challenges,Development cost,Industrial case study,Problems and Limitations,System and acceptance test automation,Visual GUI Testing},
month = {6},
number = {3},
pages = {694--744},
title = {{Visual GUI testing in practice: challenges, problemsand limitations}},
volume = {20},
year = {2015}
}

@article{Barr2015,
abstract = {Testing involves examining the behaviour of a system in order to discover potential faults. Given an input for a system, the challenge of distinguishing the corresponding desired, correct behaviour from potentially incorrect behavior is called the 'test oracle problem'. Test oracle automation is important to remove a current bottleneck that inhibits greater overall test automation. Without test oracle automation, the human has to determine whether observed behaviour is correct. The literature on test oracles has introduced techniques for oracle automation, including modelling, specifications, contract-driven development and metamorphic testing. When none of these is completely adequate, the final source of test oracle information remains the human, who may be aware of informal specifications, expectations, norms and domain specific information that provide informal oracle guidance. All forms of test oracles, even the humble human, involve challenges of reducing cost and increasing benefit. This paper provides a comprehensive survey of current approaches to the test oracle problem and an analysis of trends in this important area of software testing research and practice.},
author = {Barr, Earl T. and Harman, Mark and McMinn, Phil and Shahbaz, Muzammil and Yoo, Shin},
doi = {10.1109/TSE.2014.2372785},
issn = {0098-5589},
journal = {IEEE Transactions on Software Engineering},
keywords = {Automatic testing,Test oracle,Testing formalism},
month = {5},
number = {5},
pages = {507--525},
publisher = {IEEE},
title = {{The Oracle Problem in Software Testing: A Survey}},
volume = {41},
year = {2015}
}


@article{Cohen2015,
abstract = {We discuss a key problem in information extraction which deals with wrapper failures due to changing content templates. A good proportion of wrapper failures are due to HTML templates changing to cause wrappers to become incompatible after element inclusion or removal in a DOM (Tree representation of HTML). We perform a large-scale empirical analyses of the causes of shift and mathematically quantify the levels of domain difficulty based on entropy. We propose the XTreePath annotation method to captures contextual node information from the training DOM. We then utilize this annotation in a supervised manner at test time with our proposed Recursive Tree Matching method which locates nodes most similar in context recursively using the tree edit distance. The search is based on a heuristic function that takes into account the similarity of a tree compared to the structure that was present in the training data. We evaluate XTreePath using 117,422 pages from 75 diverse websites in 8 vertical markets. Our XTreePath method consistently outperforms XPath and a current commercial system in terms of successful extractions in a blackbox test. We make our code and datasets publicly available online.},
author = {Cohen, Joseph Paul and Ding, Wei and Bagherjeiran, Abraham},
journal = {arXiv: Information Retrieval},
month = {5},
title = {{XTreePath: A generalization of XPath to handle real world structural variation}},
year = {2015}
}

@inproceedings{Leotta2015,
abstract = {The main reason for the fragility of web test cases is the inability of web element locators to work correctly when the web page DOM evolves. Web elements locators are used in web test cases to identify all the GUI objects to operate upon and eventually to retrieve web page content that is compared against some oracle in order to decide whether the test case has passed or not. Hence, web element locators play an extremely important role in web testing and when a web element locator gets broken developers have to spend substantial time and effort to repair it. While algorithms exist to produce robust web element locators to be used in web test scripts, no algorithm is perfect and different algorithms are exposed to different fragilities when the software evolves. Based on such observation, we propose a new type of locator, named multi-locator, which selects the best locator among a candidate set of locators produced by different algorithms. Such selection is based on a voting procedure that assigns different voting weights to different locator generation algorithms. Experimental results obtained on six web applications, for which a subsequent release was available, show that the multi-locator is more robust than the single locators (about -30{\%} of broken locators w.r.t. the most robust kind of single locator) and that the execution overhead required by the multiple queries done with different locators is negligible (2-3{\%} at most).},
author = {Leotta, Maurizio and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
booktitle = {2015 IEEE 8th International Conference on Software Testing, Verification and Validation (ICST)},
keywords = {Test Case Robustness,Testware Evolution,Web Element Locators,Web Testing,XPath Locators},
month = {4},
pages = {1--10},
publisher = {IEEE},
title = {{Using Multi-Locators to Increase the Robustness of Web Test Cases}},
year = {2015}
}

@article{Alegroth2016,
abstract = {Context: Verification and validation (V{\&}V) activities make up 20-50{\%} of the total development costs of a software system in practice. Test automation is proposed to lower these V{\&}V costs but available research only provides limited empirical data from industrial practice about the maintenance costs of automated tests and what factors affect these costs. In particular, these costs and factors are unknown for automated GUI-based testing. Objective: This paper addresses this lack of knowledge through analysis of the costs and factors associated with the maintenance of automated GUI-based tests in industrial practice. Method: An empirical study at two companies, Siemens and Saab, is reported where interviews about, and empirical work with, Visual GUI Testing is performed to acquire data about the technique's maintenance costs and feasibility. Results: 13 factors are observed that affect maintenance, e.g. tester knowledge/experience and test case complexity. Further, statistical analysis shows that developing new test scripts is costlier than maintenance but also that frequent maintenance is less costly than infrequent, big bang maintenance. In addition a cost model, based on previous work, is presented that estimates the time to positive return on investment (ROI) of test automation compared to manual testing. Conclusions: It is concluded that test automation can lower overall software development costs of a project while also having positive effects on software quality. However, maintenance costs can still be considerable and the less time a company currently spends on manual testing, the more time is required before positive, economic, ROI is reached after automation.},
archivePrefix = {arXiv},
arxivId = {1602.01226},
author = {Al{\'{e}}groth, Emil and Feldt, Robert and Kolstr{\"{o}}m, Pirjo},
doi = {10.1016/j.infsof.2016.01.012},
eprint = {1602.01226},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Empirical,Industrial,Maintenance,Return on investment,Visual GUI Testing},
pages = {66--80},
title = {{Maintenance of automated test suites in industry: An empirical study on Visual GUI Testing}},
volume = {73},
year = {2016}
}

@inproceedings{Hammoudi2016,
abstract = {Software engineers often use record/replay tools to enable the automated testing of web applications. Tests created in this manner can then be used to regression test new versions of the web applications as they evolve. Web application tests recorded by record/replay tools, however, can be quite brittle, they can easily break as applications change. For this reason, researchers have begun to seek approaches for automatically repairing record/replay tests. To date, however, there have been no comprehensive attempts to characterize the causes of breakagesin record/replay tests for web applications. In this work, wepresent a taxonomy classifying the ways in which record/replay tests for web applications break, based on an analysis of 453 versions of popular web applications for which 1065 individual test breakages were recognized. The resulting taxonomy can help direct researchers in their attempts to repair such tests. It can also help practitioners by suggesting best practices when creating tests or modifying programs, and can help researchers with other tasks such as test robustness analysis and IDE design.},
author = {Hammoudi, Mouna and Rothermel, Gregg and Tonella, Paolo},
booktitle = {2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)},
keywords = {Record/replay testing,test breakages,test repair,web applications},
month = {4},
pages = {180--190},
publisher = {IEEE},
title = {{Why do Record/Replay Tests of Web Applications Break?}},
year = {2016}
}

@inproceedings{Hammoudi2016b,
abstract = {Software engineers use record replay tools to capture use case scenarios that can serve as regression tests for web applications. Such tests, however, can be brittle in the face of code changes. Thus, researchers have sought automated approaches for repairing broken record/replay tests. To date, such approaches have operated by directly analyzing differences between the releases of web applications. Often, however, intermediate versions or commits exist between releases, and these represent finer-grained sequences of changes by which new releases evolve. In this paper, we present WATERFALL, an incremental test repair approach that applies test repair techniques iteratively across a sequence of fine-grained versions of a web application. The results of an empirical study on seven web applications show that our approach is substantially more effective than a coarse-grained approach (209\% overall), while maintaining an acceptable level of overhead.},
address = {New York, NY, USA},
author = {Hammoudi, Mouna and Rothermel, Gregg and Stocco, Andrea},
booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
doi = {10.1145/2950290.2950294},
isbn = {9781450342186},
keywords = {Record/replay tests,Test case repair,Web applications},
month = {11},
pages = {751--762},
publisher = {ACM},
title = {{WATERFALL: an incremental approach for repairing record-replay tests of web applications}},
volume = {13-18-Nove},
year = {2016}
}


@article{Leotta2016,
abstract = {Automated test scripts are used with success in many web development projects, so as to automatically verify key functionalities of the web application under test, reveal possible regressions and run a large number of tests in short time. However, the adoption of automated web testing brings advantages but also novel problems, among which the test code fragility problem. During the evolution of the web application, existing test code may easily break and testers have to correct it. In the context of automated DOM-based web testing, one of the major costs for evolving the test code is the manual effort necessary to repair broken web page element locators – lines of source code identifying the web elements (e.g. form fields and buttons) to interact with. In this work, we present ROBULA+, a novel algorithm able to generate robust XPath-based locators – locators that are likely to work correctly on new releases of the web application. We compared ROBULA+ with several state of the practice/art XPath locator generator tools/algorithms. Results show that XPath locators produced by ROBULA+ are by far the most robust. Indeed, ROBULA+ reduces the locators' fragility on average by 90{\%} w.r.t. absolute locators and by 63{\%} w.r.t. Selenium IDE locators. Copyright},
author = {Leotta, Maurizio and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
journal = {Journal of Software: Evolution and Process},
keywords = {DOM selector,maintenance effort reduction,rbust XPath locator,test cases fragility,web testing},
month = {3},
number = {3},
pages = {177--204},
title = {{Robula+: an algorithm for generating robust XPath locators for web testing}},
volume = {28},
year = {2016}
}

@inproceedings{Mao2016,
abstract = {We introduce Sapienz, an approach to Android testing that uses multi-objective search-based testing to automatically explore and optimise test sequences, minimising length, while simultaneously maximising coverage and fault revelation. Sapienz combines random fuzzing, systematic and search-based exploration, exploiting seeding and multi-level instrumentation. Sapienz significantly outperforms (with large effect size) both the state-of-the-art technique Dynodroid and the widely-used tool, Android Monkey, in 7/10 experiments for coverage, 7/10 for fault detection and 10/10 for fault-revealing sequence length. When applied to the top 1,000 Google Play apps, Sapienz found 558 unique, previously unknown crashes. So far we have managed to make contact with the developers of 27 crashing apps. Of these, 14 have confirmed that the crashes are caused by real faults. Of those 14, six already have developer-confirmed fixes.},
address = {New York, NY, USA},
author = {Mao, Ke and Harman, Mark and Jia, Yue},
booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
doi = {10.1145/2931037.2931054},
isbn = {9781450343909},
keywords = {android,search-based software testing,test generation},
month = {7},
pages = {94--105},
publisher = {ACM},
title = {{Sapienz: multi-objective automated testing for Android applications}},
year = {2016}
}


@online{W3C2016,
url={https://www.w3.org/TR/1999/REC-xpath-19991116/},
title={XML Path Language (XPath)},
author={World Wide Web Consortium},
year={1999},
month={11},
urldate={2021-01-16}
}

@inproceedings{Aldalur2017,
abstract = {Web locators uniquely identify elements on the Web Content. They are heavily used in different scenarios, from Web harvesting to Web testing and browser extensions. Locators' Achilles heel is their fragility upon Website upgrades. This work tackles locator fragility in the context of browser extensions. We introduce regenerative locator, i.e. traditional structure-based locators which are supplemented with contingency data from the target node. The aim: keeping browser extensions up and running for as long as possible. Eight case studies are analysed by considering real Website upgrades taken from Wayback Machine. Figures indicate a 70{\%} success in regenerating broken locators without interrupting extension functioning.},
address = {New York, NY, USA},
author = {Aldalur, Inigo and Diaz, Oscar},
booktitle = {Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
month = {6},
pages = {45--50},
publisher = {ACM},
title = {{Addressing web locator fragility}},
year = {2017}
}

@article{Labuschagne2017,
abstract = {Software defects cost time and money to diagnose and fix. Consequently, developers use a variety of techniques to avoid introducing defects into their systems. However, these tech- niques have costs of their own; the benefit of using a technique must outweigh the cost of applying it. In this paper we investigate the costs and benefits of auto- mated regression testing in practice. Specifically, we studied 61 projects that use Travis CI, a cloud-based continuous integration tool, in order to examine real test failures that were encountered by the developers of those projects. We determined how the developers resolved the failures they encountered and used this information to classify the failures as being caused by a flaky test, by a bug in the system under test, or by a broken or obsolete test. We consider that test failures caused by bugs represent a benefit of the test suite, while failures caused by broken or obsolete tests represent a test suite maintenance cost. We found that 18{\%} of test suite executions fail and that 13{\%} of these failures are flaky. Of the non-flaky failures, only 74{\%} were caused by a bug in the system under test; the remaining 26{\%} were due to incorrect or obsolete tests. In addition, we found that, in the failed builds, only 0.38{\%} of the test case executions failed and 64{\%} of failed builds contained more than one failed test. Our findings contribute to a wider understanding of the unforeseen costs that can impact the overall cost effectiveness of regression testing in practice. They can also inform re- search into test case selection techniques, as we have provided an approximate empirical bound on the practical value that could be extracted from such techniques. This value appears to be large, as the 61 systems under study contained nearly 3 million lines of test code and yet over 99{\%} of test case executions could have been eliminated with a perfect oracle.},
author = {Labuschagne, Adriaan and Inozemtseva, Laura and Holmes, Reid},
doi = {10.1145/3106237.3106288},
isbn = {9781450351058},
journal = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering  - ESEC/FSE 2017},
pages = {821--830},
title = {{Measuring the cost of regression testing in practice: a study of Java projects using continuous integration}},
year = {2017}
}

@article{Lavoie2017,
abstract = {Context: This paper presents a novel experiment focused on detecting and analyzing clones in test suites written in TTCN-3, a standard telecommunication test script language, for different industrial projects. Objective: This paper investigates frequencies, types, and similarity distributions of TTCN-3 clones in test scripts from three industrial projects in telecommunication. We also compare the distribution of clones in TTCN-3 test scripts with the distribution of clones in C/C++ and Java projects from the telecommunication domain. We then perform a statistical analysis to validate the significance of differences between these distributions. Method: Similarity is computed using CLAN, which compares metrics syntactically derived from script fragments. Metrics are computed from the Abstract Syntax Trees produced by a TTCN-3 parser called Titan developed by Ericsson as an Eclipse plugin. Finally, clone classification of similar script pairs is computed using the Longest Common Subsequence algorithm on token types and token images. Results: This paper presents figures and diagrams reporting TTCN-3 clone frequencies, types, and similarity distributions. We show that the differences between the distribution of clones in test scripts and the distribution of clones in applications are statistically significant. We also present and discuss some lessons that can be learned about the transferability of technology from this study. Conclusion: About 24{\%} of fragments in the test suites are cloned, which is a very high proportion of clones compared to what is generally found in source code. The difference in proportion of Type-1 and Type-2 clones is statistically significant and remarkably higher in TTCN-3 than in source code. Type-1 and Type-2 clones represent 82.9{\%} and 15.3{\%} of clone fragments for a total of 98.2{\%}. Within the projects this study investigated, this represents more and easier potential re-factoring opportunities for test scripts than for code.},
author = {Lavoie, Thierry and M{\'{e}}rineau, Mathieu and Merlo, Ettore and Potvin, Pascal},
doi = {10.1016/j.infsof.2017.01.008},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Clone detection,Telecommunications software,Test},
month = {7},
pages = {32--45},
publisher = {Elsevier B.V.},
title = {{A case study of TTCN-3 test scripts clone analysis in an industrial telecommunication setting}},
volume = {87},
year = {2017}
}

@inproceedings{Levin2017,
author={S. Levin and A. Yehudai},
booktitle={2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
title={The Co-evolution of Test Maintenance and Code Maintenance through the Lens of Fine-Grained Semantic Changes},
year=2017,
pages={35-46},
doi={10.1109/ICSME.2017.9},
month={9},
}
@inproceedings{Alegroth2018,
abstract = {Continuous integration (CI) is growing in industrial popularity, spurred on by market trends towards faster delivery and higher quality software. A key facilitator of CI is automated testing that should be executed, automatically, on several levels of system abstraction. However, many systems lack the interfaces required for automated testing. Others lack test automation coverage of the system under test's (SUT) graphical user interface (GUI) as it is shown to the user. One technique that shows promise to solve these challenges is Visual GUI Testing (VGT), which uses image recognition to stimulate and assert the SUT's behavior. Research has presented the technique's applicability and feasibility in industry but only limited support, from an academic setting, that the technique is applicable in a CI environment. In this paper we presents a study from an industrial design research study with the objective to help bridge the gap in knowledge regarding VGT's applicability in a CI environment in industry. Results, acquired from interviews, observations and quantitative analysis of 17.567 test executions, collected over 16 weeks, show that VGT provides similar benefits to other automated test techniques for CI. However, several significant drawbacks, such as high costs, are also identified. The study concludes that, although VGT is applicable in an industrial CI environment, its severe challenges require more research and development before the technique becomes efficient in practice.},
author = {Alegroth, Emil and Karlsson, Arvid and Radway, Alexander},
booktitle = {2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)},
keywords = {continuous integration,design research,empirical,industrial study,visual gui testing},
month = {4},
pages = {172--181},
publisher = {IEEE},
title = {{Continuous Integration and Visual GUI Testing: Benefits and Drawbacks in Industrial Practice}},
year = {2018}
}

@inproceedings{Eladawy2018,
abstract = {The importance of test automation in the software industry has received a growing attention in recent years and it is continuously increasing. Unfortunately, the maintenance of the test cases is a major problem that faces those who use test automation. This problem becomes bigger when dealing with Graphical User Interface (GUI) tests.In this paper, an algorithm is introduced to maintain GUI tests for web applications. The Genetic algorithm is adopted to automatically repair the locators used to select elements from web pages. The algorithm is evaluated using several applications and results show that the proposed algorithm improves the repair percentage to 87\% of the used locators compared to the previous result which was 73\%.},
author = {Eladawy, Hadeel Mohamed and Mohamed, Amr E. and Salem, Sameh A.},
booktitle = {2018 13th International Conference on Computer Engineering and Systems (ICCES)},
keywords = {DOM selectors,GUI testing,XPath,XPath locator,genetic algorithm,web testing},
month = {12},
pages = {327--331},
publisher = {IEEE},
title = {{A New Algorithm for Repairing Web-Locators using Optimization Techniques}},
year = {2018}
}

@techreport{Katalon2018,
abstract = {Test automation is an essential part of modern software development lifecycles with Agile and DevOps. However, it accounts for a small percentage of test activities performed by software testing community. There are certainly challenges being faced by the community. So, understanding them is an important step to better adopt test automation in organizations. We carried out a study surveying over 2,000 software professionals about the challenges and problems faced in applying test automation. Of over 100 automation tools being used, open-source and free ones like Selenium and Katalon Studio are dominant. Functional and regression testing are the most common types adopting automation. The survey identifies the most striking challenges in applying test automation perceived by professionals with the top two being the frequently changing requirements and the lack of experienced automation resources. As implementing test automation strategies usually involves multiple tools, the difficulty in tool integration is also cited as a top challenge. The survey shows that the cost of commercial tools is the top concern when it comes to the challenges or problems with the existing automation tools. When the application under test changes, test scripts generated and maintained by tools are broken, which is the second highest challenge. The reliability of automation tools is not a key concern for many respondents.},
author = {Katalon},
number = {5},
pages = {16},
title = {{The most striking problems in test automation : A survey}},
year = {2018}
}

@article{Leotta2018,
author = {Leotta, Maurizio and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
doi = {10.1002/stvr.1665},
journal = {Software Testing, Verification and Reliability},
keywords = {DOM-based testing,Selenium WebDriver,Sikuli,Web testing,test automation,visual testing},
month = {6},
number = {4},
pages = {30},
title = {Pesto: Automated migration of DOM-based Web tests towards the visual approach}},
volume = {28},
year = {2018}
}

@inproceedings{Raffaillac2018,
author = {Raffaillac, Thibault and Huot, Stéphane},
booktitle = {Proceedings of the 30th Conference on l'Interaction Homme-Machine},
isbn = {9781450360784},
keywords = {Human-centered computing, User interface, User interface toolkits},
pages = {42--51},
publisher = {ACM},
title = {{Application du modèle Entité-Composant-Système à la programmation d'interactions Applying the Entity-Component-System Model to Interaction Programming}},
year = {2018}
}

@inproceedings{Stocco2018,
abstract = {Web tests are prone to break frequently as the application under test evolves, causing much maintenance effort in practice. To detect the root causes of a test breakage, developers typically inspect the test's interactions with the application through the GUI. Existing automated test repair techniques focus instead on the code and entirely ignore visual aspects of the application. We propose a test repair technique that is informed by a visual analysis of the application. Our approach captures relevant visual information from tests execution and analyzes them through a fast image processing pipeline to visually validate test cases as they re-executed for regression purposes. Then, it reports the occurrences of breakages and potential fixes to the testers. Our approach is also equipped with a local crawling mechanism to handle non-trivial breakage scenarios such as the ones that require to repair the test's workflow. We implemented our approach in a tool called Vista. Our empirical evaluation on 2,672 test cases spanning 86 releases of four web applications shows that Vista is able to repair, on average, 81\% of the breakages, a 41\% increment with respect to existing techniques.},
address = {Lake Buena Vista, FL, USA},
author = {Stocco, Andrea and Yandrapally, Rahulkrishna and Mesbah, Ali},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
doi = {10.1145/3236024.3236063},
isbn = {9781450355735},
keywords = {computer vision,image analysis, test repair, web testing},
month = {10},
pages = {503--514},
publisher = {ACM},
title = {{Visual web test repair}},
year = {2018}
}


@online{W3C2018,
url={https://drafts.csswg.org/selectors-3/},
title={Selectors Level 3 - W3C Candidate Recommendation},
author={World Wide Web Consortium},
year={2018},
month={1},
urldate={2021-01-21}
}


@inproceedings{Zheng2018,
abstract = {Due to the rapid iteration of Web applications, there are some broken test cases in regression tests. The main reason for the appearance of broken test cases is the failure of element location in the new web page. The element locators in the test cases come from various Web element locating tools, which are used to identify the elements to be convenient for testers to operate them and eventually to test the Web application. Therefore, the Web element locating tools play an essential role in web testing. At present, there are some Web element locating tools, which are supported by a single locating algorithm or multiple locating algorithms. Moreover, the Multi-Locators supported by multiple algorithms are obviously more robust than the one supported by a single algorithm. However, when synthesizing all locating algorithm to generate Multi-Locators, a better method can be selected in assigning weights to each algorithm. Based on this observation, we propose a method to optimize Multi-Locators. In assigning weight to each algorithm, it chooses a weight distribution method based on machine learning, named Learned Weights. Through experimental comparison, it is shown that the locating tool supported by algorithm based on machine learning is more robust than these existing locating tools.},
author = {Zheng, Yu and Huang, Song and Hui, Zhan-wei and Wu, Ya-Ning},
booktitle = {2018 IEEE International Conference on Software Quality, Reliability and Security Companion (QRS-C)},
keywords = {Learned Weights,Web Element Locating Tool,Web Locator,Web Testing},
month = {7},
pages = {172--174},
publisher = {IEEE},
title = {{A Method of Optimizing Multi-Locators Based on Machine Learning}},
year = {2018}
}

@inproceedings{Biagiola2019,
abstract = {Existing web test generators derive test paths from a navigational model of the web application, completed with either manually or randomly generated input values. However, manual test data selec- tion is costly, while random generation often results in infeasible input sequences, which are rejected by the application under test. Random and search-based generation can achieve the desired level of model coverage only after a large number of test execution at- tempts, each slowed down by the need to interact with the browser during test execution. In this work, we present a novel web test generation algorithm that pre-selects the most promising candi- date test cases based on their diversity from previously generated tests. As such, only the test cases that explore diverse behaviours of the application are considered for in-browser execution. We have implemented our approach in a tool called DIG. Our empirical eval- uation on six real-world web applications shows that DIG achieves higher coverage and fault detection rates significantly earlier than crawling-based and search-based web test generators.},
address = {Tallinn, Estonia},
author = {Biagiola, Matteo and Stocco, Andrea and Ricca, Filippo and Tonella, Paolo},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering - ESEC/FSE 2019},
doi = {10.1145/3338906.3338970},
isbn = {9781450355728},
keywords = {diversity,page object,test generation,web testing},
number = {1},
pages = {142--153},
publisher = {ACM Press},
title = {{Diversity-based web test generation}},
year = {2019}
}

@incollection{Canny2019,
abstract = {Testing interactive systems is known to be a complex task that cannot be exhaustive. Indeed, the infinite number of combination of user input and the complexity of information presentation exceed the practical limits of exhaustive and analytical approach to testing [31]. Most interactive software testing techniques are produced by applying and tuning techniques from the field of software testing to try to address the specificities of interactive applications. When some elements cannot be taken into account by the software testing technique, they are usually ignored. In this paper we propose to follow an opposite approach, starting from a generic architecture for interactive systems (including both software and hardware elements) for identifying in a systematic way, testing problems and testing needs. This architecture-driven approach makes it possible to identify how software testing knowledge and techniques can support interactive systems testing but also where the interactive systems engineering community should invest in order to test their idiosyncrasies too.},
author = {Canny, Alexandre and Bouzekri, Elodie and Martinie, C{\'{e}}lia and Palanque, Philippe},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-05909-5_10},
isbn = {9783030059088},
issn = {16113349},
keywords = {Architecture-driven testing,Interactive system testing},
pages = {164--186},
title = {{Rationalizing the Need of Architecture-Driven Testing of Interactive Systems}},
volume = {11262 LNCS},
year = {2019}
}

@article{Coppola2019,
abstract = {Android applications do not seem to be tested as thoroughly as desktop ones. In particular, graphical user interface (GUI) testing appears generally limited. Like web-based applications, mobile apps suffer from GUI test fragility, i.e., GUI test classes failing or needing updates due to even minor modifications in the GUI or in the application under test. The objective of our study is to estimate the adoption of GUI testing frameworks among Android open-source applications, the quantity of modifications needed to keep test classes up to date, and their amount due to GUI test fragility. We introduce a set of 21 metrics to measure the adoption of testing tools and the evolution of test classes and test methods, and to estimate the fragility of test suites. We computed our metrics for six GUI testing frameworks, none of which achieved a significant adoption among Android projects hosted on GitHub. When present, GUI test methods associated with the considered tools are modified often, and a relevant portion (70\% on average) of those modifications is induced by GUI-related fragilities. On average, for the projects considered, more than 7\% of the total modified lines of code between consecutive releases belong to test classes developed with the analyzed testing frameworks. The measured percentage was higher on average than the one required by other generic test code, based on the JUnit testing framework. Fragility of GUI tests constitutes a relevant concern, probably an obstacle for developers to adopt test automation. This first evaluation of the fragility of Android scripted GUI testing can constitute a benchmark for developers and testers leveraging the analyzed test tools and the basis for the definition of a taxonomy of fragility causes and guidelines to mitigate the issue.},
author = {Coppola, Riccardo and Morisio, Maurizio and Torchiano, Marco},
doi = {10.1109/TR.2018.2869227},
issn = {0018-9529},
journal = {IEEE Transactions on Reliability},
keywords = {Mobile computing,software engineering,software maintenance,software metrics,software testing},
month = {3},
number = {1},
pages = {67--90},
publisher = {IEEE},
title = {{Mobile GUI Testing Fragility: A Study on Open-Source Android Applications}},
volume = {68},
year = {2019}
}


@online{Grigorik2019,
url={https://developers.google.com/web/fundamentals/performance/critical-rendering-path/render-tree-construction},
title={Render-tree Construction, Layout, and Paint},
author={Grigorik, Ilya},
year={2019},
month={2},
urldate={2021-01-28}
}


@inproceedings{Kirinuki2019,
abstract = {Test automation tools such as Selenium are commonly used for automating end-to-end tests, but when developers update the software, they often need to modify the test scripts accordingly. However, the costs of modifying these test scripts are a big obstacle to test automation because of the scripts' fragility. In particular, locators in test scripts are prone to change. Some prior methods tried to repair broken locators by using structural clues, but these approaches usually cannot handle radical changes to page layouts. In this paper, we propose a novel approach called COLOR (correct locator recommender) to support repairing broken locators in accordance with software updates. COLOR uses various properties as clues obtained from screens (i.e., attributes, texts, images, and positions). We examined which properties are reliable for recommending locators by examining changes between two release versions of software, and the reliability is adopted as the weight of a property. Our experimental results obtained from four open source web applications show that COLOR can present the correct locator in rst place with a 77{\%}-93{\%} accuracy and is more robust against page layout changes than structure-based approaches.},
author = {Kirinuki, Hiroyuki and Tanno, Haruto and Natsukawa, Katsuyuki},
booktitle = {2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)},
month = {2},
number = {4},
pages = {310--320},
publisher = {IEEE},
title = {{COLOR: Correct Locator Recommender for Broken Test Scripts using Various Clues in Web Application}},
volume = {36},
year = {2019}
}

@inproceedings{Rwemalika2019,
abstract = {Many companies rely on software testing to verify that their software products meet their requirements. However, test quality and, in particular, the quality of end-to-end testing is relatively hard to achieve. The problem becomes challenging when software evolves, as end-to-end test suites need to adapt and conform to the evolved software. Unfortunately, end-to-end tests are particularly fragile as any change in the application interface, e.g., application flow, location or name of graphical user interface elements, necessitates a change in the tests. This paper presents an industrial case study on the evolution of Keyword-Driven test suites, also known as Keyword-Driven Testing (KDT). Our aim is to demonstrate the problem of test maintenance, identify the benefits of Keyword-Driven Testing and overall improve the understanding of test code evolution (at the acceptance testing level). This information will support the development of automatic techniques, such as test refactoring and repair, and will motivate future research. To this end, we identify, collect and analyze test code changes across the evolution of industrial KDT test suites for a period of eight months. We show that the problem of test maintenance is largely due to test fragility (most commonly-performed changes are due to locator and synchronization issues) and test clones (over 30{\%} of keywords are duplicated). We also show that the better test design of KDT test suites has the potential for drastically reducing (approximately 70{\%}) the number of test code changes required to support software evolution. To further validate our results, we interview testers from BGL BNP Paribas and report their perceptions on the advantages and challenges of keyword-driven testing.},
address = {Xi'an, China},
author = {Rwemalika, Renaud and Kintis, Marinos and Papadakis, Mike and {Le Traon}, Yves and Lorrach, Pierre},
booktitle = {2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)},
keywords = {acceptance testing,end-to-end testing,keyword-driven testing,test clone,test code evolution},
month = {4},
pages = {335--345},
publisher = {IEEE},
title = {{On the Evolution of Keyword-Driven Test Suites}},
year = {2019}
}

@inproceedings{Canny2020,
abstract = {The testing of applications with a Graphical User Interface (GUI) is a complex activity because of the infinity of possible event sequences. In the field of GUI Testing, model-based approaches based on reverse engineering of GUI application have been proposed to generate test cases. Unfortunately, evidences show that these techniques do not support some of the features of modern GUI applications. These features include dynamic widgets instantiation or advanced interaction techniques (e.g. multitouch). In this paper, we propose to build models of the applications from requirements, as it is standard practice in Model-Based Testing. To do so, we identified ICO (Interactive Cooperative Object) as one of the modelling techniques allowing the description of complex GUI behavior. We demonstrate that this notation is suitable for generating test cases targeting complex GUI applications in a process derived from the standard ModelBased Testing process.},
author = {Canny, Alexandre and Palanque, Philippe and Navarre, David},
booktitle = {2020 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)},
doi = {10.1109/ICSTW50294.2020.00029},
isbn = {978-1-7281-1075-2},
keywords = {GUI Testing,Model-Based Testing,User Interface Description Languages},
month = {10},
pages = {95--104},
publisher = {IEEE},
title = {{Model-Based Testing of GUI Applications Featuring Dynamic Instanciation of Widgets}},
year = {2020}
}


@online{Google2020,
url={https://developer.android.com/studio/test/monkey},
title={UI/Application Exerciser Monkey},
author={Google},
year={2020},
month={8},
urldate={2021-05-15}
}

@online{MDN2020,
url={https://developer.mozilla.org/en-US/docs/Web/HTML/Element},
title={HTML elements reference},
author={MDN contributors},
year={2020},
month={12},
urldate={2021-01-16}
}

@online{RobotFramework2020,
author = {Robot RobotFramework},
title = {Introduction},
year = 2020,
url = {http://robotframework.org/},
urldate = {2021-02-15}
}

@article{DiMartino2021,
abstract = {Exploratory testing and fully automated testing tools represent two viable and cheap alternatives to traditional test-case-based approaches for graphical user interface (GUI) testing of Android apps. The former can be executed by capture and replay tools that directly translate execution scenarios registered by testers in test cases, without requiring preliminary test-case design and advanced programming/testing skills. The latter tools are able to test Android GUIs without tester intervention. Even if these two strategies are widely employed, to the best of our knowledge, no empirical investigation has been performed to compare their performance and obtain useful insights for a project manager to establish an effective testing strategy. In this paper, we present two experiments we carried out to compare the effectiveness of exploratory testing approaches using a capture and replay tool (Robotium Recorder) against three freely available automatic testing tools (AndroidRipper, Sapienz, and Google Robo). The first experiment involved 20 computer engineering students who were asked to record testing executions, under strict temporal limits and no access to the source code. Results were slightly better than those of fully automated tools, but not in a conclusive way. In the second experiment, the same students were asked to improve the achieved testing coverage by exploiting the source code and the coverage obtained in the previous tests, without strict temporal constraints. The results of this second experiment showed that students outperformed the automated tools especially for long/complex execution scenarios. The obtained findings provide useful indications for deciding testing strategies that combine manual exploratory testing and automated testing.},
author = {{Di Martino}, Sergio and Fasolino, Anna Rita and Starace, Luigi Libero Lucio and Tramontana, Porfirio},
doi = {10.1002/stvr.1754},
issn = {0960-0833},
journal = {Software Testing, Verification and Reliability},
keywords = {Android app testing,GUI testing,automatic input generation,capture and replay,testing effectiveness},
month = {5},
number = {3},
title = {{Comparing the effectiveness of capture and replay against automatic input generation for Android graphical user interface testing}},
volume = {31},
year = {2021}
}


@online{WHATWG2021,
url={https://html.spec.whatwg.org/},
title={HTML Living Standard},
author={Web Hypertext Application Technology Working Group},
year={2021},
month={1},
urldate={2021-01-16}
}

@online{Selenium2021,
url={https://www.selenium.dev/documentation/en/getting_started_with_webdriver/locating_elements/},
title={Locating elements},
author={Software Freedom Conservancy},
year={2021},
month={1},
urldate={2021-01-19}
}