\chapter{Related Work}
\label{related}

\section{Test code evolution}
\label{related-evolution}

In the literature, we find a great amount of work tackling the problem of test code evolution. For instance \citep{Zaidman2011} and \citep{Levin2017} analyze the co-evolution between test code and production code. \citep{Levin2017} analyze 61 open source projects to establish a relationship between test maintenance and production code maintenance. They create a model to see what type of changes in the code base cause maintenance of the test suite.

\citep{Pinto2012} analyze the evolution of test suites and extract actions performed on the test suite in order to see how the test suite is evolving. They conclude that test repair occurs in practice and that it is not due to only assertion fixes and suggest further research of automatic repair tools. Although this work is similar to ours, the focus of the study is the unit level while we focus on the acceptance level.

To the best of our knowledge, \citep{Skoglund2004} were the first to conduct an empirical study on the evolution of system level tests. The authors conduct an exploratory analysis to investigate potential test suite maintenance issues. They explore three strategies to minimize the number of changes in the test code resulting from a production code change. Their study found that in one strategy, more changes were needed to maintain the test code while with the other no changes were needed to the unit test code. However, since their dataset is synthetic, they only draw qualitative conclusions.

\citep{Grechanik2009} perform a cost-benefit analysis of tool-based GUI-based application (GAP) functional test suites versus manual maintenance. They describe a case study with 45 professional programmers and test engineers. They show that the automated GUI testing approach (QTP) reports more broken test script statements due to changes in GUI with fewer false positives than the manual approach. However, they recommend against the tool-based repair approach for experienced test engineers because of the high cost of each license and the low added value.

\citep{Shewchuk2010} create a functional test suite using the tool IRFT for the open source project JEdit. In their work, they measure the effort to create and maintain the test suite and compared its size and number of changes against the production code. They conclude that the method to create test using IRFT is effective, with respect of the effort needed to develop and maintain functional test suites as well as the fault detection capabilities of those suites. One limitation of this study is that it uses synthetic test suites.

\citep{Alegroth2013} and \citep{Alegroth2016} analyze the costs and factors associated with the maintenance of Visual GUI testing (VGT) based on an empirical study. They identified 13 factors influencing maintenance. Their work shows that the cost of creation is much higher than the cost of maintenance. They also show that the cost of maintenance can be reduced by frequent evolutions instead of few big changes. Lastly, the authors build a cost model comparing manual testing to automated testing. They conclude that the return on investment of using VGT is positive.

In their work, \citep{Labuschagne2017} explore the cost and benefits of automated regression testing in practice. To do so, they select 61 projects and analyze their test execution reports. They show that in some cases tests break because of invalid assumption and that maintenance cost could be reduced via the use of better development processes.

Similarly, in \cite{Kan2013}, the authors attempt to build a cost model comparing manual testing and automated testing. This model answer the question whether or not it is cheaper to create and maintain an automated test or to perform manual testing. (Journal doesn't seem so great)

Another similar study is the one of \citep{Lavoie2017} who analyzed potential code duplication in TTNC-3 test scripts in industrial telecommunication software. Their findings suggest that 24\% of the code fragments in the test suites are clones. We find analogous evidence of the presence of clones in KDT test code.

Although much work has been conducted on test evolution, work on acceptance testing code evolution is still scarce. In this study, we try to fill this gap and provide quantitative and qualitative data on the cost and benefits of creating and maintaining KDT in practice.

%The major difference between our work and the aforementioned ones is that we focus on acceptance-level, KDT test suites. Our results XXX The work of XXX is the most similar to ours but XXX.

\section{Test code fragility}

\section{Repairing test code}

Finally, an alternative to trying to build more robust locators is to automatically repair tests suffering from locator breakages. Different tools are proposed in the literature trying to leverage different properties of the page such as attribute properties in the passing tests\cite{Choudhary2011} constants in the GUI representation\cite{Kirinuki2019} or relying on computer vision\cite{Stocco2018} to regenerate broken locators. Because these techniques focus on the root causes of locator breakages and the ways to fix them, lessons can be learned on how to generate less fragile locators.

\section{Creating less fragile test code}

The problem of the impact of DOM evolution on locators is not new in the research community. First attempts at solving this problem come from the information retrieval community\cite{Anton2005, Dalvi2009, Cohen2015}. However, they target different elements in the DOM (wrappers) presenting significant differences to the ones used for automation testing.

Other approaches to generate more robust second-generation locators for GUI-base testing can be found in the literature. \citep{Leotta2014, Leotta2016} and \citep{Montoto2011} propose algorithms to generate more robust XPath. The resulting locators are a fully compliant XPath and thus while algorithms are very efficient at generating robust XPath, they still suffer from the same drawbacks in terms of lack of flexibility. 

Other approaches propose to enrich the locators with additional information. Some authors\cite{Leotta2015, Zheng2018} propose a multi-locator approach which combines different XPath in order to generate more robust locators. Their results suggest that the combination of multiple location paths yields more robust locators. Closer to our work, \citep{Thummalapenta2013} and later \citep{Yandrapally2014} propose approaches to extract contextual clues from the GUI to augment the information contained in the locator and avoid to rely too heavily on the structure of the DOM. However, those approaches focuses only on the proximity of labels and if it cannot find any falls back to XPath. We argue that the HTML document contains more contextual information that can be leverage during the construction of the locator.